{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Con Tensorflow\n",
    "\n",
    "Tomado del curso [Deep Learning con Tensorflow para Machine Learning e IA](https://www.udemy.com/course/tensorflow-python/) del profesor [Juan Gabriel Gomila Salas](https://github.com/joanby/tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones en el grafo de computación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.array([2.,4.,6.,8.,10.,12.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m_const = tf.constant(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ y = mx = 3x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_1:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_product = tf.multiply(m_const, x_data)\n",
    "my_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "12.0\n",
      "18.0\n",
      "24.0\n",
      "30.0\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(my_product, feed_dict = {x_data: x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 12. 18. 24. 30. 36.]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_product, feed_dict = {x_data: x_vals}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6., 12., 18., 24., 30., 36.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.multiply(m_const, x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones por capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  5.,  7.],\n",
       "       [-2.,  0.,  7.,  6.],\n",
       "       [-6., -1.,  0.,  3.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array = np.array([[1.,3.,5.,7.],\n",
    "                    [-2.,0.,7.,6.],\n",
    "                    [-6.,-1.,0.,3.]])\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  3.,  5.,  7.],\n",
       "        [-2.,  0.,  7.,  6.],\n",
       "        [-6., -1.,  0.,  3.]],\n",
       "\n",
       "       [[ 2.,  4.,  6.,  8.],\n",
       "        [-1.,  1.,  8.,  7.],\n",
       "        [-5.,  0.,  1.,  4.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals = np.array([my_array, my_array+1])\n",
    "x_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=(3,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m1 = tf.constant([[1.],[0.],[-2.],[5.]])\n",
    "m2 = tf.constant([[7.]])\n",
    "a1 = tf.constant([[15.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$(X\\cdot m_1)m_2+a_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prod1 = tf.matmul(x_data, m1)\n",
    "prod2 = tf.matmul(prod1, m2)\n",
    "add1 = tf.add(prod2, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197.]\n",
      " [113.]\n",
      " [ 78.]]\n",
      "[[225.]\n",
      " [141.]\n",
      " [106.]]\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(add1, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Trabajar con múltiples capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "# session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.06128026],\n",
       "         [0.87156032],\n",
       "         [0.72401941],\n",
       "         [0.60112092]],\n",
       "\n",
       "        [[0.8891606 ],\n",
       "         [0.28728361],\n",
       "         [0.83489501],\n",
       "         [0.40807198]],\n",
       "\n",
       "        [[0.7320763 ],\n",
       "         [0.75241017],\n",
       "         [0.79797285],\n",
       "         [0.77101396]],\n",
       "\n",
       "        [[0.76440585],\n",
       "         [0.00251679],\n",
       "         [0.54689621],\n",
       "         [0.13860781]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape = [1,4,4,1]\n",
    "x_val = np.random.uniform(size = x_shape)\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape = x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_filter = tf.constant(0.25, shape = [2,2,1,1])\n",
    "my_strides = [1,2,2,1]\n",
    "mov_avg_layer = tf.nn.conv2d(x_data, my_filter,my_strides, padding='SAME', name='Moving_Average_Wnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\frac{W-F+2P}{S}+1$$\n",
    "\n",
    "- W : dimensión de entrada\n",
    "- F: Dimensión del filtro\n",
    "- P: Padding\n",
    "- S: Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_layer(input_matrix):\n",
    "    input_matrix_squeezed  =tf.squeeze(input_matrix)\n",
    "    A = tf.constant([[1.,2.],[3.,4.]])\n",
    "    b = tf.constant(1., shape=[2,2])\n",
    "    temp1 = tf.matmul(A, input_matrix_squeezed)\n",
    "    temp2 = tf.add(temp1, b)\n",
    "    return tf.sigmoid(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Custom_layer\") as scope:\n",
    "    customlayer1 = custom_layer(mov_avg_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9341972 , 0.94099253],\n",
       "       [0.9921033 , 0.9944067 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(customlayer1, feed_dict={x_data: x_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('multiple-layes', session.graph)\n",
    "session.run(customlayer1, feed_dict={x_data: x_val})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida en predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-1.,1.,500)\n",
    "target = tf.constant(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L2 (distancia Euclidiana)\n",
    "\n",
    "$$L2(y_r, y_p) = \\sqrt{\\sum(y_r-y_p)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_y_vals = tf.square(target-x_vals)\n",
    "l2_y_out = session.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338.6773162148966\n"
     ]
    }
   ],
   "source": [
    "l2_y_vals = tf.sqrt(tf.reduce_sum(tf.square(target-x_vals)))\n",
    "l2_y_out = session.run(l2_y_vals)\n",
    "print((l2_y_out**2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.667336"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.nn.l2_loss(target-x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L1\n",
    "\n",
    "$$L1(y_r,y_p)=|y_r-y_p|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_vals = tf.abs(target-x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_out = session.run(l1_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.995992   0.99198395 0.98797596 0.98396796 0.9799599\n",
      " 0.9759519  0.9719439  0.96793586 0.96392787 0.9599198  0.9559118\n",
      " 0.9519038  0.94789577 0.94388777 0.9398798  0.9358717  0.9318637\n",
      " 0.92785573 0.9238477  0.9198397  0.9158317  0.91182363 0.90781564\n",
      " 0.90380764 0.8997996  0.8957916  0.8917836  0.88777554 0.88376755\n",
      " 0.87975955 0.8757515  0.8717435  0.8677355  0.86372745 0.85971946\n",
      " 0.8557114  0.8517034  0.8476954  0.84368736 0.83967936 0.8356713\n",
      " 0.8316633  0.8276553  0.82364726 0.81963927 0.8156313  0.8116232\n",
      " 0.8076152  0.8036072  0.7995992  0.7955912  0.7915832  0.7875751\n",
      " 0.78356713 0.77955914 0.7755511  0.7715431  0.7675351  0.76352704\n",
      " 0.75951904 0.75551105 0.751503   0.747495   0.743487   0.73947895\n",
      " 0.73547095 0.73146296 0.7274549  0.72344685 0.7194389  0.71543086\n",
      " 0.7114228  0.70741487 0.7034068  0.69939876 0.6953908  0.69138277\n",
      " 0.6873747  0.6833667  0.6793587  0.67535067 0.6713427  0.6673347\n",
      " 0.6633266  0.6593186  0.65531063 0.6513026  0.6472946  0.6432866\n",
      " 0.63927853 0.63527054 0.63126254 0.6272545  0.6232465  0.6192385\n",
      " 0.61523044 0.61122245 0.60721445 0.6032064  0.5991984  0.5951904\n",
      " 0.59118235 0.58717436 0.58316636 0.5791583  0.57515025 0.5711423\n",
      " 0.56713426 0.5631262  0.5591183  0.5551102  0.55110216 0.5470942\n",
      " 0.5430862  0.5390781  0.5350701  0.5310621  0.5270541  0.5230461\n",
      " 0.5190381  0.51503    0.51102203 0.50701404 0.503006   0.498998\n",
      " 0.49499    0.49098194 0.48697394 0.48296595 0.4789579  0.4749499\n",
      " 0.4709419  0.46693385 0.46292585 0.45891786 0.4549098  0.4509018\n",
      " 0.44689375 0.44288576 0.43887776 0.4348697  0.4308617  0.42685372\n",
      " 0.42284566 0.41883767 0.41482967 0.41082162 0.40681362 0.40280563\n",
      " 0.39879757 0.39478958 0.39078158 0.38677353 0.38276553 0.37875754\n",
      " 0.37474948 0.3707415  0.36673343 0.36272544 0.35871744 0.3547094\n",
      " 0.3507014  0.3466934  0.34268534 0.33867735 0.33466935 0.3306613\n",
      " 0.3266533  0.3226453  0.31863725 0.31462926 0.31062126 0.3066132\n",
      " 0.3026052  0.29859716 0.29458916 0.29058117 0.2865731  0.28256512\n",
      " 0.27855712 0.27454907 0.27054107 0.26653308 0.26252502 0.25851703\n",
      " 0.25450903 0.25050098 0.24649298 0.24248499 0.23847693 0.23446894\n",
      " 0.23046088 0.22645289 0.22244489 0.21843684 0.21442884 0.21042085\n",
      " 0.20641279 0.2024048  0.1983968  0.19438875 0.19038075 0.18637276\n",
      " 0.1823647  0.1783567  0.17434871 0.17034066 0.16633266 0.16232467\n",
      " 0.15831661 0.15430862 0.15030056 0.14629257 0.14228457 0.13827652\n",
      " 0.13426852 0.13026053 0.12625247 0.12224448 0.11823648 0.11422843\n",
      " 0.11022043 0.10621244 0.10220438 0.09819639 0.09418839 0.09018034\n",
      " 0.08617234 0.08216429 0.07815629 0.0741483  0.07014024 0.06613225\n",
      " 0.06212425 0.0581162  0.0541082  0.05010021 0.04609215 0.04208416\n",
      " 0.03807616 0.03406811 0.03006011 0.02605212 0.02204406 0.01803607\n",
      " 0.01402807 0.01002002 0.00601202 0.00200397 0.00200403 0.00601208\n",
      " 0.01002002 0.01402807 0.01803613 0.02204406 0.02605212 0.03006017\n",
      " 0.03406811 0.03807616 0.04208422 0.04609215 0.05010021 0.05410826\n",
      " 0.0581162  0.06212425 0.06613231 0.07014024 0.0741483  0.07815635\n",
      " 0.08216429 0.08617234 0.0901804  0.09418833 0.09819639 0.10220444\n",
      " 0.1062125  0.11022043 0.11422849 0.11823654 0.12224448 0.12625253\n",
      " 0.13026059 0.13426852 0.13827658 0.14228463 0.14629257 0.15030062\n",
      " 0.15430868 0.15831661 0.16232467 0.16633272 0.17034066 0.17434871\n",
      " 0.17835677 0.1823647  0.18637276 0.19038081 0.19438875 0.1983968\n",
      " 0.20240486 0.20641279 0.21042085 0.2144289  0.21843684 0.22244489\n",
      " 0.22645295 0.23046088 0.23446894 0.23847699 0.24248493 0.24649298\n",
      " 0.25050104 0.2545091  0.25851703 0.26252508 0.26653314 0.27054107\n",
      " 0.27454913 0.27855718 0.28256512 0.28657317 0.29058123 0.29458916\n",
      " 0.29859722 0.30260527 0.3066132  0.31062126 0.31462932 0.31863725\n",
      " 0.3226453  0.32665336 0.3306613  0.33466935 0.3386774  0.34268534\n",
      " 0.3466934  0.35070145 0.3547094  0.35871744 0.3627255  0.36673343\n",
      " 0.3707415  0.37474954 0.37875748 0.38276553 0.3867736  0.39078152\n",
      " 0.39478958 0.39879763 0.4028057  0.40681362 0.41082168 0.41482973\n",
      " 0.41883767 0.42284572 0.42685378 0.4308617  0.43486977 0.43887782\n",
      " 0.44288576 0.4468938  0.45090187 0.4549098  0.45891786 0.4629259\n",
      " 0.46693385 0.4709419  0.47494996 0.4789579  0.48296595 0.486974\n",
      " 0.49098194 0.49499    0.49899805 0.503006   0.50701404 0.5110221\n",
      " 0.51503    0.5190381  0.52304614 0.5270541  0.5310621  0.5350702\n",
      " 0.53907824 0.5430862  0.5470942  0.5511023  0.5551102  0.5591183\n",
      " 0.5631263  0.56713426 0.5711423  0.5751504  0.5791583  0.58316636\n",
      " 0.5871744  0.59118235 0.5951904  0.59919846 0.6032064  0.60721445\n",
      " 0.6112225  0.61523044 0.6192385  0.62324655 0.6272545  0.63126254\n",
      " 0.6352706  0.63927853 0.6432866  0.64729464 0.6513026  0.65531063\n",
      " 0.6593187  0.6633266  0.6673347  0.67134273 0.67535067 0.6793587\n",
      " 0.6833668  0.68737483 0.69138277 0.6953908  0.6993989  0.7034068\n",
      " 0.70741487 0.7114229  0.71543086 0.7194389  0.72344697 0.7274549\n",
      " 0.73146296 0.735471   0.73947895 0.743487   0.74749506 0.751503\n",
      " 0.75551105 0.7595191  0.76352704 0.7675351  0.77154315 0.7755511\n",
      " 0.77955914 0.7835672  0.7875751  0.7915832  0.79559124 0.7995992\n",
      " 0.8036072  0.8076153  0.8116232  0.8156313  0.8196393  0.82364726\n",
      " 0.8276553  0.83166337 0.8356714  0.83967936 0.8436874  0.84769547\n",
      " 0.8517034  0.85571146 0.8597195  0.86372745 0.8677355  0.87174356\n",
      " 0.8757515  0.87975955 0.8837676  0.88777554 0.8917836  0.89579165\n",
      " 0.8997996  0.90380764 0.9078157  0.91182363 0.9158317  0.91983974\n",
      " 0.9238477  0.92785573 0.9318638  0.9358717  0.9398798  0.9438878\n",
      " 0.94789577 0.9519038  0.9559119  0.9599198  0.96392787 0.9679359\n",
      " 0.97194386 0.9759519  0.97995996 0.983968   0.98797596 0.991984\n",
      " 0.99599206 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(l1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Huber\n",
    "\n",
    "$$PH(y_r,y_p) = \\delta^2 \\cdot \\sqrt{1+\\left(\\frac{y_r-y_p}{\\delta}\\right)^2}-1, \\delta > 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1.+tf.square((target-x_vals)/delta1))-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9957012  0.99170107 0.98770094 0.9837009  0.9797009  0.9757009\n",
      " 0.971701   0.9677013  0.96370155 0.9597019  0.9557023  0.95170283\n",
      " 0.94770336 0.9437039  0.9397047  0.93570554 0.9317064  0.9277073\n",
      " 0.92370826 0.9197093  0.9157106  0.9117118  0.90771306 0.9037145\n",
      " 0.899716   0.89571756 0.8917192  0.88772094 0.8837227  0.87972486\n",
      " 0.87572676 0.87172884 0.8677311  0.8637334  0.8597358  0.8557383\n",
      " 0.8517408  0.8477435  0.8437463  0.8397492  0.8357522  0.8317552\n",
      " 0.82775843 0.82376164 0.8197651  0.81576866 0.8117724  0.8077761\n",
      " 0.80377996 0.79978395 0.7957881  0.7917923  0.78779674 0.7838012\n",
      " 0.7798058  0.77581054 0.7718153  0.76782036 0.76382554 0.75983065\n",
      " 0.7558363  0.7518418  0.7478474  0.7438533  0.7398593  0.7358655\n",
      " 0.7318717  0.7278782  0.7238848  0.7198915  0.71589863 0.71190566\n",
      " 0.7079129  0.70392036 0.699928   0.6959358  0.6919438  0.6879519\n",
      " 0.6839602  0.67996883 0.6759776  0.6719865  0.66799563 0.664005\n",
      " 0.6600145  0.65602434 0.65203434 0.64804447 0.64405495 0.6400656\n",
      " 0.6360764  0.6320876  0.6280989  0.6241105  0.62012243 0.6161345\n",
      " 0.612147   0.60815954 0.60417247 0.6001857  0.59619915 0.5922129\n",
      " 0.58822685 0.5842413  0.5802559  0.5762708  0.57228607 0.56830186\n",
      " 0.5643177  0.5603339  0.5563506  0.5523675  0.54838485 0.5444026\n",
      " 0.5404206  0.53643906 0.53245795 0.5284772  0.5244968  0.52051693\n",
      " 0.5165375  0.51255846 0.5085798  0.50460166 0.50062394 0.49664685\n",
      " 0.49267018 0.48869395 0.4847183  0.48074314 0.47676855 0.47279453\n",
      " 0.4688211  0.46484813 0.46087593 0.45690423 0.45293316 0.44896284\n",
      " 0.444993   0.44102404 0.4370557  0.43308806 0.42912114 0.4251551\n",
      " 0.4211897  0.41722518 0.41326153 0.40929863 0.40533662 0.40137562\n",
      " 0.39741537 0.39345622 0.389498   0.38554075 0.38158464 0.37762955\n",
      " 0.37367553 0.36972275 0.36577103 0.36182064 0.35787147 0.35392356\n",
      " 0.34997708 0.34603193 0.34208822 0.338146   0.33420536 0.33026618\n",
      " 0.32632872 0.32239306 0.31845903 0.31452692 0.31059667 0.30666837\n",
      " 0.30274218 0.29881802 0.2948962  0.29097664 0.2870594  0.2831447\n",
      " 0.2792326  0.27532315 0.27141654 0.26751292 0.26361227 0.25971484\n",
      " 0.25582078 0.25193015 0.24804324 0.24416012 0.24028094 0.236406\n",
      " 0.2325354  0.22866948 0.22480841 0.22095235 0.21710172 0.21325669\n",
      " 0.20941752 0.20558473 0.20175852 0.19793923 0.19412735 0.1903233\n",
      " 0.18652742 0.18274038 0.17896266 0.17519473 0.17143738 0.16769122\n",
      " 0.16395696 0.16023543 0.15652749 0.15283415 0.1491564  0.14549534\n",
      " 0.14185227 0.13822857 0.13462561 0.13104518 0.12748899 0.123959\n",
      " 0.12045749 0.11698689 0.11354978 0.11014923 0.1067885  0.1034712\n",
      " 0.10020149 0.09698381 0.09382325 0.09072535 0.08769628 0.08474298\n",
      " 0.08187306 0.07909485 0.07641769 0.07385168 0.07140782 0.06909804\n",
      " 0.066935   0.06493206 0.06310315 0.06146235 0.0600236  0.05880036\n",
      " 0.05780495 0.0570481  0.05653849 0.05628211 0.05628212 0.05653849\n",
      " 0.0570481  0.05780495 0.05880038 0.0600236  0.06146235 0.06310318\n",
      " 0.06493206 0.066935   0.06909807 0.07140782 0.07385168 0.07641773\n",
      " 0.07909485 0.08187306 0.08474303 0.08769628 0.09072535 0.09382329\n",
      " 0.09698381 0.10020149 0.10347126 0.10678845 0.11014923 0.11354981\n",
      " 0.11698694 0.12045749 0.12395904 0.12748905 0.13104518 0.13462566\n",
      " 0.1382286  0.14185227 0.14549538 0.14915647 0.15283415 0.15652753\n",
      " 0.1602355  0.16395696 0.16769122 0.17143746 0.17519473 0.17896266\n",
      " 0.18274045 0.18652742 0.1903233  0.19412741 0.19793923 0.20175852\n",
      " 0.2055848  0.20941752 0.21325669 0.21710177 0.22095235 0.22480841\n",
      " 0.22866955 0.2325354  0.236406   0.240281   0.24416006 0.24804324\n",
      " 0.2519302  0.25582087 0.25971484 0.2636123  0.26751298 0.27141654\n",
      " 0.2753232  0.27923268 0.2831447  0.28705946 0.29097667 0.2948962\n",
      " 0.2988181  0.30274224 0.30666837 0.31059667 0.31452698 0.31845903\n",
      " 0.32239306 0.3263288  0.33026618 0.33420536 0.33814606 0.34208822\n",
      " 0.34603193 0.3499771  0.35392356 0.35787147 0.3618207  0.36577103\n",
      " 0.36972275 0.37367558 0.3776295  0.38158464 0.38554084 0.38949794\n",
      " 0.39345622 0.39741546 0.40137565 0.40533662 0.4092987  0.41326156\n",
      " 0.41722518 0.42118976 0.42515516 0.42912114 0.43308806 0.43705577\n",
      " 0.44102404 0.44499305 0.44896284 0.45293316 0.45690423 0.46087596\n",
      " 0.46484813 0.4688211  0.47279453 0.47676855 0.48074314 0.48471835\n",
      " 0.48869395 0.49267018 0.4966469  0.50062394 0.50460166 0.50857985\n",
      " 0.51255846 0.5165375  0.520517   0.5244968  0.5284772  0.532458\n",
      " 0.5364391  0.5404206  0.5444026  0.54838496 0.5523675  0.5563506\n",
      " 0.560334   0.5643177  0.56830186 0.5722862  0.5762708  0.5802559\n",
      " 0.58424133 0.58822685 0.5922129  0.59619915 0.6001857  0.60417247\n",
      " 0.6081596  0.612147   0.6161345  0.62012243 0.6241105  0.6280989\n",
      " 0.63208765 0.6360764  0.6400656  0.64405495 0.64804447 0.65203434\n",
      " 0.6560244  0.6600145  0.664005   0.66799563 0.6719865  0.6759776\n",
      " 0.6799689  0.68396044 0.6879519  0.6919438  0.6959359  0.699928\n",
      " 0.70392036 0.707913   0.71190566 0.71589863 0.7198916  0.7238848\n",
      " 0.7278782  0.7318718  0.7358655  0.7398593  0.74385333 0.7478474\n",
      " 0.7518418  0.7558363  0.75983065 0.76382554 0.7678205  0.7718153\n",
      " 0.77581054 0.77980584 0.7838012  0.78779674 0.7917923  0.7957881\n",
      " 0.79978395 0.80378    0.8077761  0.8117724  0.81576866 0.8197651\n",
      " 0.82376164 0.8277585  0.83175534 0.8357522  0.83974916 0.8437464\n",
      " 0.8477435  0.85174084 0.85573834 0.8597358  0.8637334  0.86773115\n",
      " 0.87172884 0.87572676 0.8797248  0.8837227  0.88772094 0.8917193\n",
      " 0.89571756 0.899716   0.9037146  0.90771306 0.9117118  0.9157106\n",
      " 0.9197093  0.92370826 0.9277074  0.9317064  0.93570554 0.9397048\n",
      " 0.9437039  0.94770336 0.95170283 0.9557023  0.9597019  0.96370167\n",
      " 0.9677012  0.971701   0.9757009  0.9797009  0.9837009  0.98770094\n",
      " 0.9917011  0.9957012 ]\n"
     ]
    }
   ],
   "source": [
    "phuber1_y_out = session.run(phuber1_y_vals)\n",
    "print(phuber1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida para problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-3.,5.,500)\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([500,],1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge (función bisagra)\n",
    "\n",
    "$$H(y_r,y_p)=max(0, 1-y_r\\cdot y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.         3.983968   3.9679358  3.9519038  3.9358718  3.9198396\n",
      " 3.9038076  3.8877757  3.8717434  3.8557115  3.8396792  3.8236473\n",
      " 3.8076153  3.791583   3.775551   3.759519   3.743487   3.727455\n",
      " 3.711423   3.6953907  3.6793587  3.6633267  3.6472945  3.6312625\n",
      " 3.6152306  3.5991983  3.5831664  3.5671344  3.5511022  3.5350702\n",
      " 3.5190382  3.503006   3.486974   3.470942   3.4549098  3.4388778\n",
      " 3.4228456  3.4068136  3.3907816  3.3747494  3.3587174  3.3426852\n",
      " 3.3266532  3.3106213  3.294589   3.278557   3.262525   3.2464929\n",
      " 3.230461   3.214429   3.1983967  3.1823647  3.1663327  3.1503005\n",
      " 3.1342685  3.1182365  3.1022043  3.0861723  3.0701404  3.0541081\n",
      " 3.0380762  3.0220442  3.006012   2.98998    2.973948   2.9579158\n",
      " 2.9418838  2.9258518  2.9098196  2.8937874  2.8777556  2.8617234\n",
      " 2.8456912  2.8296595  2.8136272  2.797595   2.7815633  2.765531\n",
      " 2.7494988  2.7334669  2.717435   2.7014027  2.6853707  2.6693387\n",
      " 2.6533065  2.6372745  2.6212425  2.6052103  2.5891783  2.5731463\n",
      " 2.5571141  2.5410821  2.5250502  2.509018   2.492986   2.476954\n",
      " 2.4609218  2.4448898  2.4288578  2.4128256  2.3967936  2.3807616\n",
      " 2.3647294  2.3486974  2.3326654  2.3166332  2.300601   2.2845693\n",
      " 2.268537   2.2525048  2.236473   2.2204409  2.2044086  2.188377\n",
      " 2.1723447  2.1563125  2.1402805  2.1242485  2.1082163  2.0921843\n",
      " 2.0761523  2.06012    2.0440881  2.0280561  2.012024   1.995992\n",
      " 1.97996    1.9639277  1.9478958  1.9318638  1.9158316  1.8997996\n",
      " 1.8837676  1.8677354  1.8517034  1.8356714  1.8196392  1.8036072\n",
      " 1.787575   1.771543   1.755511   1.7394788  1.7234468  1.7074149\n",
      " 1.6913826  1.6753507  1.6593187  1.6432865  1.6272545  1.6112225\n",
      " 1.5951903  1.5791583  1.5631263  1.5470941  1.5310621  1.5150301\n",
      " 1.4989979  1.482966   1.4669337  1.4509017  1.4348698  1.4188375\n",
      " 1.4028056  1.3867736  1.3707414  1.3547094  1.3386774  1.3226452\n",
      " 1.3066132  1.2905812  1.274549   1.258517   1.242485   1.2264528\n",
      " 1.2104208  1.1943886  1.1783566  1.1623247  1.1462924  1.1302605\n",
      " 1.1142285  1.0981963  1.0821643  1.0661323  1.0501001  1.0340681\n",
      " 1.0180361  1.0020039  0.9859719  0.96993995 0.9539077  0.93787575\n",
      " 0.9218435  0.90581155 0.88977957 0.87374735 0.85771537 0.8416834\n",
      " 0.82565117 0.8096192  0.7935872  0.777555   0.761523   0.745491\n",
      " 0.7294588  0.7134268  0.69739485 0.6813626  0.66533065 0.64929867\n",
      " 0.63326645 0.61723447 0.60120225 0.58517027 0.5691383  0.55310607\n",
      " 0.5370741  0.5210421  0.5050099  0.4889779  0.47294593 0.4569137\n",
      " 0.44088173 0.42484975 0.40881753 0.39278555 0.37675357 0.36072135\n",
      " 0.34468937 0.32865715 0.31262517 0.2965932  0.28056097 0.264529\n",
      " 0.24849701 0.23246479 0.21643281 0.20040083 0.18436861 0.16833663\n",
      " 0.15230465 0.13627243 0.12024045 0.10420847 0.08817625 0.07214427\n",
      " 0.05611229 0.04008007 0.02404809 0.00801587 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "hinge_y_vals = tf.maximum(0., 1.0 - tf.multiply(target, x_vals))\n",
    "hinge_y_out = session.run(hinge_y_vals)\n",
    "print(hinge_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada (función logística)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log(y_p) - (1-y_r)\\cdot log(1-y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 4.266695   3.504558   3.07711    2.7786188\n",
      " 2.5490425  2.3624578  2.205273   2.0694702  1.9499258  1.8431584\n",
      " 1.7466972  1.658729   1.5778773  1.5030754  1.4334824  1.3684192\n",
      " 1.307331   1.2497613  1.1953264  1.1437016  1.0946122  1.0478203\n",
      " 1.0031197  0.96033263 0.9193009  0.8798871  0.8419681  0.805434\n",
      " 0.7701883  0.7361426  0.7032175  0.67134243 0.64045215 0.61048704\n",
      " 0.58139426 0.55312395 0.5256306  0.49887323 0.4728133  0.44741485\n",
      " 0.4226459  0.39847532 0.37487555 0.35181987 0.3292835  0.30724418\n",
      " 0.2856801  0.26457092 0.24389847 0.2236447  0.20379275 0.18432751\n",
      " 0.16523395 0.14649788 0.12810664 0.11004756 0.09230857 0.07487902\n",
      " 0.05774807 0.0409054  0.02434197 0.00804817        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    }
   ],
   "source": [
    "xentr_y_vals = -tf.multiply(target, tf.log(x_vals)) - tf.multiply((1.-target), tf.log(1.-x_vals))\n",
    "xentr_y_out = session.run(xentr_y_vals)\n",
    "print(xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada de sigmoide (evitar nans)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log\\left(\\frac{1}{1+e^{-y_p}}\\right) - (1-y_r)\\cdot log\\left(1-\\frac{1}{1+e^{-y_p}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0485873  3.0333216  3.0180674  3.0028253  2.9875953  2.9723773\n",
      " 2.9571722  2.9419796  2.9267998  2.9116333  2.8964796  2.8813396\n",
      " 2.866213   2.8511002  2.8360016  2.8209174  2.805847   2.7907915\n",
      " 2.7757509  2.7607253  2.7457147  2.7307198  2.7157404  2.700777\n",
      " 2.6858296  2.6708984  2.6559842  2.6410863  2.6262057  2.6113422\n",
      " 2.5964963  2.581668   2.5668578  2.5520658  2.5372922  2.5225375\n",
      " 2.5078013  2.493085   2.4783878  2.4637103  2.4490528  2.4344156\n",
      " 2.419799   2.4052036  2.3906288  2.3760755  2.3615441  2.3470345\n",
      " 2.332547   2.3180823  2.3036401  2.2892213  2.2748258  2.2604537\n",
      " 2.246106   2.2317827  2.2174835  2.2032096  2.188961   2.174738\n",
      " 2.1605408  2.14637    2.1322253  2.1181078  2.1040173  2.0899544\n",
      " 2.0759194  2.0619125  2.0479343  2.0339847  2.0200646  2.006174\n",
      " 1.9923133  1.978483   1.964683   1.9509143  1.9371768  1.923471\n",
      " 1.9097973  1.8961561  1.8825476  1.8689723  1.8554305  1.8419226\n",
      " 1.828449   1.8150101  1.8016063  1.7882378  1.7749051  1.7616086\n",
      " 1.7483487  1.7351258  1.7219402  1.7087922  1.6956824  1.6826111\n",
      " 1.6695787  1.6565857  1.6436323  1.630719   1.6178461  1.6050141\n",
      " 1.5922233  1.5794743  1.5667672  1.5541027  1.5414809  1.5289024\n",
      " 1.5163676  1.5038767  1.4914304  1.4790288  1.4666724  1.4543618\n",
      " 1.4420971  1.4298787  1.4177072  1.4055829  1.393506   1.3814772\n",
      " 1.3694968  1.357565   1.3456825  1.3338494  1.3220662  1.3103331\n",
      " 1.2986509  1.2870194  1.2754395  1.2639112  1.252435   1.2410114\n",
      " 1.2296406  1.2183228  1.2070587  1.1958485  1.1846924  1.1735909\n",
      " 1.1625443  1.1515529  1.1406174  1.1297374  1.1189138  1.1081467\n",
      " 1.0974362  1.0867832  1.0761876  1.0656495  1.0551697  1.0447482\n",
      " 1.0343852  1.0240812  1.0138364  1.0036507  0.993525   0.9834591\n",
      " 0.97345334 0.9635081  0.9536234  0.94379973 0.9340371  0.92433566\n",
      " 0.9146959  0.9051178  0.8956015  0.8861475  0.87675565 0.8674262\n",
      " 0.8581595  0.8489556  0.83981436 0.83073646 0.8217216  0.81277007\n",
      " 0.803882   0.7950575  0.7862966  0.7775996  0.7689662  0.7603969\n",
      " 0.75189155 0.7434501  0.735073   0.7267599  0.7185109  0.7103263\n",
      " 0.7022059  0.6941497  0.6861577  0.67823017 0.6703666  0.66256744\n",
      " 0.6548323  0.64716154 0.63955474 0.632012   0.62453336 0.61711866\n",
      " 0.6097677  0.6024806  0.5952571  0.5880972  0.5810008  0.5739678\n",
      " 0.5669979  0.5600912  0.5532474  0.54646635 0.5397481  0.5330923\n",
      " 0.5264987  0.51996744 0.51349795 0.5070903  0.5007442  0.49445942\n",
      " 0.48823592 0.48207334 0.47597137 0.46992996 0.46394876 0.45802754\n",
      " 0.45216608 0.44636413 0.4406213  0.43493748 0.4293124  0.4237456\n",
      " 0.418237   0.4127862  0.40739292 0.4020569  0.39677775 0.39155528\n",
      " 0.38638905 0.38127875 0.3762242  0.37122494 0.36628062 0.361391\n",
      " 0.35655573 0.35177428 0.3470466  0.34237215 0.33775058 0.33318156\n",
      " 0.3286648  0.32419977 0.31978628 0.3154238  0.31111214 0.30685073\n",
      " 0.30263945 0.2984776  0.294365   0.2903013  0.28628597 0.28231865\n",
      " 0.27839914 0.27452683 0.27070138 0.26692253 0.2631897  0.25950256\n",
      " 0.25586087 0.252264   0.24871165 0.24520354 0.24173906 0.2383179\n",
      " 0.23493983 0.23160417 0.22831067 0.22505905 0.22184868 0.21867928\n",
      " 0.21555042 0.21246186 0.20941298 0.20640348 0.20343307 0.20050117\n",
      " 0.19760749 0.19475172 0.19193329 0.18915193 0.18640728 0.18369885\n",
      " 0.1810263  0.17838936 0.17578746 0.17322034 0.17068763 0.16818888\n",
      " 0.16572374 0.16329196 0.16089298 0.15852652 0.15619229 0.15388978\n",
      " 0.1516187  0.14937878 0.14716949 0.14499056 0.1428417  0.14072245\n",
      " 0.13863249 0.1365716  0.13453922 0.13253517 0.13055909 0.12861057\n",
      " 0.12668931 0.12479503 0.1229274  0.12108601 0.11927059 0.11748087\n",
      " 0.11571644 0.11397702 0.11226235 0.11057204 0.1089058  0.1072634\n",
      " 0.10564445 0.10404868 0.10247584 0.10092555 0.09939756 0.09789165\n",
      " 0.09640741 0.09494463 0.09350307 0.09208237 0.09068228 0.08930258\n",
      " 0.08794292 0.08660308 0.08528284 0.08398185 0.0826999  0.08143677\n",
      " 0.08019212 0.07896577 0.07775748 0.07656694 0.07539396 0.07423832\n",
      " 0.07309971 0.07197795 0.07087281 0.06978408 0.06871147 0.0676548\n",
      " 0.06661386 0.06558841 0.06457823 0.06358314 0.06260289 0.06163729\n",
      " 0.06068617 0.05974926 0.05882638 0.05791738 0.05702201 0.05614009\n",
      " 0.05527147 0.0544159  0.05357321 0.05274327 0.05192582 0.05112073\n",
      " 0.05032782 0.04954689 0.04877779 0.04802036 0.04727439 0.04653975\n",
      " 0.04581628 0.04510379 0.04440213 0.04371117 0.04303072 0.04236063\n",
      " 0.04170077 0.04105099 0.04041111 0.03978101 0.03916057 0.03854959\n",
      " 0.03794797 0.03735558 0.03677225 0.03619787 0.03563231 0.03507543\n",
      " 0.0345271  0.0339872  0.0334556  0.03293218 0.03241682 0.03190939\n",
      " 0.03140978 0.03091788 0.03043356 0.02995671 0.02948724 0.029025\n",
      " 0.02856991 0.02812186 0.02768073 0.02724643 0.02681887 0.02639791\n",
      " 0.02598347 0.02557547 0.02517379 0.02477833 0.02438902 0.02400575\n",
      " 0.02362843 0.02325697 0.0228913  0.0225313  0.02217689 0.02182801\n",
      " 0.02148456 0.02114644 0.02081361 0.02048595 0.02016339 0.01984588\n",
      " 0.0195333  0.0192256  0.01892272 0.01862455 0.01833104 0.01804211\n",
      " 0.0177577  0.01747772 0.01720214 0.01693085 0.01666381 0.01640095\n",
      " 0.0161422  0.0158875  0.01563678 0.01539    0.01514707 0.01490796\n",
      " 0.01467259 0.01444091 0.01421286 0.01398839 0.01376744 0.01354996\n",
      " 0.01333589 0.01312517 0.01291777 0.01271363 0.01251268 0.0123149\n",
      " 0.01212022 0.0119286  0.01174    0.01155436 0.01137163 0.01119178\n",
      " 0.01101477 0.01084053 0.01066904 0.01050024 0.0103341  0.01017058\n",
      " 0.01000963 0.00985122 0.0096953  0.00954184 0.00939079 0.00924212\n",
      " 0.0090958  0.00895179 0.00881004 0.00867053 0.00853322 0.00839807\n",
      " 0.00826506 0.00813414 0.00800529 0.00787847 0.00775366 0.00763081\n",
      " 0.0075099  0.0073909  0.00727378 0.00715851 0.00704506 0.0069334\n",
      " 0.00682351 0.00671535]\n"
     ]
    }
   ],
   "source": [
    "xentr_sig_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_vals, labels = targets)\n",
    "xentr_sig_y_out = session.run(xentr_sig_y_vals)\n",
    "print(xentr_sig_y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5242937  1.5166608  1.5090337  1.5014126  1.4937977  1.4861887\n",
      " 1.4785861  1.4709898  1.4633999  1.4558166  1.4482398  1.4406698\n",
      " 1.4331065  1.4255501  1.4180008  1.4104587  1.4029235  1.3953958\n",
      " 1.3878754  1.3803626  1.3728573  1.3653599  1.3578702  1.3503885\n",
      " 1.3429148  1.3354492  1.3279921  1.3205432  1.3131028  1.3056711\n",
      " 1.2982482  1.290834   1.2834289  1.2760329  1.2686461  1.2612687\n",
      " 1.2539006  1.2465425  1.2391939  1.2318552  1.2245264  1.2172078\n",
      " 1.2098995  1.2026018  1.1953144  1.1880378  1.1807721  1.1735172\n",
      " 1.1662735  1.1590412  1.1518201  1.1446106  1.1374129  1.1302269\n",
      " 1.123053   1.1158913  1.1087418  1.1016048  1.0944805  1.087369\n",
      " 1.0802704  1.073185   1.0661126  1.0590539  1.0520086  1.0449772\n",
      " 1.0379597  1.0309563  1.0239671  1.0169923  1.0100323  1.003087\n",
      " 0.99615663 0.9892415  0.9823415  0.97545713 0.9685884  0.9617355\n",
      " 0.95489866 0.94807804 0.9412738  0.93448615 0.92771524 0.9209613\n",
      " 0.9142245  0.90750504 0.90080315 0.8941189  0.88745254 0.8808043\n",
      " 0.87417436 0.8675629  0.8609701  0.8543961  0.8478412  0.84130555\n",
      " 0.83478934 0.82829285 0.82181615 0.8153595  0.80892307 0.80250704\n",
      " 0.79611164 0.78973716 0.7833836  0.7770513  0.77074045 0.7644512\n",
      " 0.7581838  0.75193834 0.7457152  0.7395144  0.7333362  0.7271809\n",
      " 0.72104853 0.71493936 0.7088536  0.70279145 0.696753   0.6907386\n",
      " 0.6847484  0.6787825  0.67284125 0.6669247  0.6610331  0.65516657\n",
      " 0.64932543 0.6435097  0.63771975 0.6319556  0.6262175  0.6205057\n",
      " 0.6148203  0.6091614  0.60352933 0.59792423 0.5923462  0.58679545\n",
      " 0.5812721  0.57577646 0.5703087  0.5648687  0.5594569  0.55407333\n",
      " 0.5487181  0.5433916  0.5380938  0.53282475 0.52758485 0.5223741\n",
      " 0.5171926  0.5120406  0.5069182  0.50182533 0.4967625  0.49172956\n",
      " 0.48672667 0.48175406 0.4768117  0.47189987 0.46701854 0.46216783\n",
      " 0.45734796 0.4525589  0.44780076 0.44307375 0.43837783 0.4337131\n",
      " 0.42907974 0.4244778  0.41990718 0.41536823 0.4108608  0.40638503\n",
      " 0.401941   0.39752874 0.3931483  0.3887998  0.3844831  0.38019845\n",
      " 0.37594578 0.37172505 0.3675365  0.36337996 0.35925546 0.35516316\n",
      " 0.35110295 0.34707484 0.34307885 0.33911508 0.3351833  0.33128372\n",
      " 0.32741615 0.32358077 0.31977737 0.316006   0.31226668 0.30855933\n",
      " 0.30488384 0.3012403  0.29762855 0.2940486  0.2905004  0.2869839\n",
      " 0.28349894 0.2800456  0.2766237  0.27323318 0.26987404 0.26654616\n",
      " 0.26324934 0.25998372 0.25674897 0.25354514 0.2503721  0.24722971\n",
      " 0.24411796 0.24103667 0.23798569 0.23496498 0.23197438 0.22901377\n",
      " 0.22608304 0.22318207 0.22031064 0.21746874 0.2146562  0.2118728\n",
      " 0.2091185  0.2063931  0.20369646 0.20102845 0.19838887 0.19577764\n",
      " 0.19319452 0.19063938 0.1881121  0.18561247 0.18314031 0.1806955\n",
      " 0.17827787 0.17588714 0.1735233  0.17118607 0.16887529 0.16659078\n",
      " 0.1643324  0.16209988 0.15989314 0.1577119  0.15555607 0.15342537\n",
      " 0.15131973 0.1492388  0.1471825  0.14515065 0.14314298 0.14115933\n",
      " 0.13919957 0.13726342 0.13535069 0.13346127 0.13159485 0.12975128\n",
      " 0.12793043 0.126132   0.12435582 0.12260177 0.12086953 0.11915895\n",
      " 0.11746991 0.11580209 0.11415534 0.11252952 0.11092434 0.10933964\n",
      " 0.10777521 0.10623093 0.10470649 0.10320174 0.10171653 0.10025059\n",
      " 0.09880374 0.09737586 0.09596664 0.09457596 0.09320364 0.09184942\n",
      " 0.09051315 0.08919468 0.08789373 0.08661017 0.08534382 0.08409444\n",
      " 0.08286187 0.08164598 0.08044649 0.07926326 0.07809614 0.07694489\n",
      " 0.07580935 0.07468939 0.07358474 0.07249528 0.07142085 0.07036123\n",
      " 0.06931625 0.0682858  0.06726961 0.06626759 0.06527954 0.06430528\n",
      " 0.06334466 0.06239751 0.0614637  0.060543   0.0596353  0.05874044\n",
      " 0.05785822 0.05698851 0.05613118 0.05528602 0.0544529  0.0536317\n",
      " 0.05282222 0.05202434 0.05123792 0.05046277 0.04969878 0.04894583\n",
      " 0.04820371 0.04747232 0.04675154 0.04604118 0.04534114 0.04465129\n",
      " 0.04397146 0.04330154 0.04264142 0.04199092 0.04134995 0.04071838\n",
      " 0.04009606 0.03948288 0.03887874 0.03828347 0.03769698 0.03711916\n",
      " 0.03654986 0.03598898 0.0354364  0.03489204 0.03435573 0.0338274\n",
      " 0.03330693 0.0327942  0.03228911 0.03179157 0.03130144 0.03081865\n",
      " 0.03034308 0.02987463 0.02941319 0.02895869 0.02851101 0.02807005\n",
      " 0.02763574 0.02720795 0.02678661 0.02637164 0.02596291 0.02556036\n",
      " 0.02516391 0.02477345 0.0243889  0.02401018 0.0236372  0.02326987\n",
      " 0.02290814 0.0225519  0.02220107 0.02185559 0.02151536 0.02118032\n",
      " 0.02085038 0.02052549 0.02020556 0.01989051 0.01958028 0.0192748\n",
      " 0.01897398 0.01867779 0.01838612 0.01809894 0.01781616 0.01753771\n",
      " 0.01726355 0.0169936  0.0167278  0.01646609 0.01620841 0.0159547\n",
      " 0.01570489 0.01545894 0.01521678 0.01497835 0.01474362 0.0145125\n",
      " 0.01428495 0.01406093 0.01384037 0.01362322 0.01340943 0.01319895\n",
      " 0.01299174 0.01278774 0.01258689 0.01238917 0.01219451 0.01200288\n",
      " 0.01181422 0.01162849 0.01144565 0.01126565 0.01108845 0.01091401\n",
      " 0.01074228 0.01057322 0.0104068  0.01024297 0.0100817  0.00992294\n",
      " 0.00976665 0.0096128  0.00946136 0.00931227 0.00916552 0.00902106\n",
      " 0.00887885 0.00873886 0.00860107 0.00846543 0.00833191 0.00820047\n",
      " 0.0080711  0.00794375 0.00781839 0.007695   0.00757354 0.00745398\n",
      " 0.00733629 0.00722045 0.00710643 0.0069942  0.00688372 0.00677498\n",
      " 0.00666794 0.00656259 0.00645888 0.00635681 0.00625634 0.00615745\n",
      " 0.00606011 0.0059643  0.00587    0.00577718 0.00568582 0.00559589\n",
      " 0.00550738 0.00542026 0.00533452 0.00525012 0.00516705 0.00508529\n",
      " 0.00500482 0.00492561 0.00484765 0.00477092 0.0046954  0.00462106\n",
      " 0.0045479  0.00447589 0.00440502 0.00433527 0.00426661 0.00419904\n",
      " 0.00413253 0.00406707 0.00400264 0.00393924 0.00387683 0.0038154\n",
      " 0.00375495 0.00369545 0.00363689 0.00357925 0.00352253 0.0034667\n",
      " 0.00341175 0.00335767]\n"
     ]
    }
   ],
   "source": [
    "pos_weight = tf.constant(0.5)\n",
    "xentr_sig_w_y_vals = tf.nn.weighted_cross_entropy_with_logits(logits=x_vals, targets = targets, pos_weight = pos_weight)\n",
    "xentr_sig_w_y_out = session.run(xentr_sig_w_y_vals)\n",
    "print(xentr_sig_w_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Cross Entropy (probabilidad)\n",
    "\n",
    "$$SM(z_k) = \\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1601256]\n"
     ]
    }
   ],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[0.1,0.02,0.88]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse softmax cross entropy (vector 0s y un 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[2]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar las funciones de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_array = session.run(x_vals)\n",
    "plt.plot(x_array, l2_y_out, 'r-', label='L2')\n",
    "plt.plot(x_array, l1_y_out, 'g--', label='L1')\n",
    "plt.plot(x_array, phuber1_y_out, 'b-.', label='Pseudo Huber (0.25)')\n",
    "plt.ylim(-0.2, 2)\n",
    "plt.legend(loc = 'lower right', prop={'size': 10})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
