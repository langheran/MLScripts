{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Con Tensorflow\n",
    "\n",
    "Tomado del curso [Deep Learning con Tensorflow para Machine Learning e IA](https://www.udemy.com/course/tensorflow-python/) del profesor [Juan Gabriel Gomila Salas](https://github.com/joanby/tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones en el grafo de computación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.array([2.,4.,6.,8.,10.,12.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m_const = tf.constant(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ y = mx = 3x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_1:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_product = tf.multiply(m_const, x_data)\n",
    "my_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "12.0\n",
      "18.0\n",
      "24.0\n",
      "30.0\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(my_product, feed_dict = {x_data: x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 12. 18. 24. 30. 36.]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_product, feed_dict = {x_data: x_vals}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6., 12., 18., 24., 30., 36.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.multiply(m_const, x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones por capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  5.,  7.],\n",
       "       [-2.,  0.,  7.,  6.],\n",
       "       [-6., -1.,  0.,  3.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array = np.array([[1.,3.,5.,7.],\n",
    "                    [-2.,0.,7.,6.],\n",
    "                    [-6.,-1.,0.,3.]])\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  3.,  5.,  7.],\n",
       "        [-2.,  0.,  7.,  6.],\n",
       "        [-6., -1.,  0.,  3.]],\n",
       "\n",
       "       [[ 2.,  4.,  6.,  8.],\n",
       "        [-1.,  1.,  8.,  7.],\n",
       "        [-5.,  0.,  1.,  4.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals = np.array([my_array, my_array+1])\n",
    "x_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=(3,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m1 = tf.constant([[1.],[0.],[-2.],[5.]])\n",
    "m2 = tf.constant([[7.]])\n",
    "a1 = tf.constant([[15.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$(X\\cdot m_1)m_2+a_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prod1 = tf.matmul(x_data, m1)\n",
    "prod2 = tf.matmul(prod1, m2)\n",
    "add1 = tf.add(prod2, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197.]\n",
      " [113.]\n",
      " [ 78.]]\n",
      "[[225.]\n",
      " [141.]\n",
      " [106.]]\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(add1, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Trabajar con múltiples capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "# session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.06128026],\n",
       "         [0.87156032],\n",
       "         [0.72401941],\n",
       "         [0.60112092]],\n",
       "\n",
       "        [[0.8891606 ],\n",
       "         [0.28728361],\n",
       "         [0.83489501],\n",
       "         [0.40807198]],\n",
       "\n",
       "        [[0.7320763 ],\n",
       "         [0.75241017],\n",
       "         [0.79797285],\n",
       "         [0.77101396]],\n",
       "\n",
       "        [[0.76440585],\n",
       "         [0.00251679],\n",
       "         [0.54689621],\n",
       "         [0.13860781]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape = [1,4,4,1]\n",
    "x_val = np.random.uniform(size = x_shape)\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape = x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_filter = tf.constant(0.25, shape = [2,2,1,1])\n",
    "my_strides = [1,2,2,1]\n",
    "mov_avg_layer = tf.nn.conv2d(x_data, my_filter,my_strides, padding='SAME', name='Moving_Average_Wnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\frac{W-F+2P}{S}+1$$\n",
    "\n",
    "- W : dimensión de entrada\n",
    "- F: Dimensión del filtro\n",
    "- P: Padding\n",
    "- S: Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_layer(input_matrix):\n",
    "    input_matrix_squeezed  =tf.squeeze(input_matrix)\n",
    "    A = tf.constant([[1.,2.],[3.,4.]])\n",
    "    b = tf.constant(1., shape=[2,2])\n",
    "    temp1 = tf.matmul(A, input_matrix_squeezed)\n",
    "    temp2 = tf.add(temp1, b)\n",
    "    return tf.sigmoid(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Custom_layer\") as scope:\n",
    "    customlayer1 = custom_layer(mov_avg_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9341972 , 0.94099253],\n",
       "       [0.9921033 , 0.9944067 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(customlayer1, feed_dict={x_data: x_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('multiple-layes', session.graph)\n",
    "session.run(customlayer1, feed_dict={x_data: x_val})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida en predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-1.,1.,500)\n",
    "target = tf.constant(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L2 (distancia Euclidiana)\n",
    "\n",
    "$$L2(y_r, y_p) = \\sqrt{\\sum(y_r-y_p)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_y_vals = tf.square(target-x_vals)\n",
    "l2_y_out = session.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338.6773162148966\n"
     ]
    }
   ],
   "source": [
    "l2_y_vals = tf.sqrt(tf.reduce_sum(tf.square(target-x_vals)))\n",
    "l2_y_out = session.run(l2_y_vals)\n",
    "print((l2_y_out**2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.667336"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.nn.l2_loss(target-x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L1\n",
    "\n",
    "$$L1(y_r,y_p)=|y_r-y_p|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_vals = tf.abs(target-x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_out = session.run(l1_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.995992   0.99198395 0.98797596 0.98396796 0.9799599\n",
      " 0.9759519  0.9719439  0.96793586 0.96392787 0.9599198  0.9559118\n",
      " 0.9519038  0.94789577 0.94388777 0.9398798  0.9358717  0.9318637\n",
      " 0.92785573 0.9238477  0.9198397  0.9158317  0.91182363 0.90781564\n",
      " 0.90380764 0.8997996  0.8957916  0.8917836  0.88777554 0.88376755\n",
      " 0.87975955 0.8757515  0.8717435  0.8677355  0.86372745 0.85971946\n",
      " 0.8557114  0.8517034  0.8476954  0.84368736 0.83967936 0.8356713\n",
      " 0.8316633  0.8276553  0.82364726 0.81963927 0.8156313  0.8116232\n",
      " 0.8076152  0.8036072  0.7995992  0.7955912  0.7915832  0.7875751\n",
      " 0.78356713 0.77955914 0.7755511  0.7715431  0.7675351  0.76352704\n",
      " 0.75951904 0.75551105 0.751503   0.747495   0.743487   0.73947895\n",
      " 0.73547095 0.73146296 0.7274549  0.72344685 0.7194389  0.71543086\n",
      " 0.7114228  0.70741487 0.7034068  0.69939876 0.6953908  0.69138277\n",
      " 0.6873747  0.6833667  0.6793587  0.67535067 0.6713427  0.6673347\n",
      " 0.6633266  0.6593186  0.65531063 0.6513026  0.6472946  0.6432866\n",
      " 0.63927853 0.63527054 0.63126254 0.6272545  0.6232465  0.6192385\n",
      " 0.61523044 0.61122245 0.60721445 0.6032064  0.5991984  0.5951904\n",
      " 0.59118235 0.58717436 0.58316636 0.5791583  0.57515025 0.5711423\n",
      " 0.56713426 0.5631262  0.5591183  0.5551102  0.55110216 0.5470942\n",
      " 0.5430862  0.5390781  0.5350701  0.5310621  0.5270541  0.5230461\n",
      " 0.5190381  0.51503    0.51102203 0.50701404 0.503006   0.498998\n",
      " 0.49499    0.49098194 0.48697394 0.48296595 0.4789579  0.4749499\n",
      " 0.4709419  0.46693385 0.46292585 0.45891786 0.4549098  0.4509018\n",
      " 0.44689375 0.44288576 0.43887776 0.4348697  0.4308617  0.42685372\n",
      " 0.42284566 0.41883767 0.41482967 0.41082162 0.40681362 0.40280563\n",
      " 0.39879757 0.39478958 0.39078158 0.38677353 0.38276553 0.37875754\n",
      " 0.37474948 0.3707415  0.36673343 0.36272544 0.35871744 0.3547094\n",
      " 0.3507014  0.3466934  0.34268534 0.33867735 0.33466935 0.3306613\n",
      " 0.3266533  0.3226453  0.31863725 0.31462926 0.31062126 0.3066132\n",
      " 0.3026052  0.29859716 0.29458916 0.29058117 0.2865731  0.28256512\n",
      " 0.27855712 0.27454907 0.27054107 0.26653308 0.26252502 0.25851703\n",
      " 0.25450903 0.25050098 0.24649298 0.24248499 0.23847693 0.23446894\n",
      " 0.23046088 0.22645289 0.22244489 0.21843684 0.21442884 0.21042085\n",
      " 0.20641279 0.2024048  0.1983968  0.19438875 0.19038075 0.18637276\n",
      " 0.1823647  0.1783567  0.17434871 0.17034066 0.16633266 0.16232467\n",
      " 0.15831661 0.15430862 0.15030056 0.14629257 0.14228457 0.13827652\n",
      " 0.13426852 0.13026053 0.12625247 0.12224448 0.11823648 0.11422843\n",
      " 0.11022043 0.10621244 0.10220438 0.09819639 0.09418839 0.09018034\n",
      " 0.08617234 0.08216429 0.07815629 0.0741483  0.07014024 0.06613225\n",
      " 0.06212425 0.0581162  0.0541082  0.05010021 0.04609215 0.04208416\n",
      " 0.03807616 0.03406811 0.03006011 0.02605212 0.02204406 0.01803607\n",
      " 0.01402807 0.01002002 0.00601202 0.00200397 0.00200403 0.00601208\n",
      " 0.01002002 0.01402807 0.01803613 0.02204406 0.02605212 0.03006017\n",
      " 0.03406811 0.03807616 0.04208422 0.04609215 0.05010021 0.05410826\n",
      " 0.0581162  0.06212425 0.06613231 0.07014024 0.0741483  0.07815635\n",
      " 0.08216429 0.08617234 0.0901804  0.09418833 0.09819639 0.10220444\n",
      " 0.1062125  0.11022043 0.11422849 0.11823654 0.12224448 0.12625253\n",
      " 0.13026059 0.13426852 0.13827658 0.14228463 0.14629257 0.15030062\n",
      " 0.15430868 0.15831661 0.16232467 0.16633272 0.17034066 0.17434871\n",
      " 0.17835677 0.1823647  0.18637276 0.19038081 0.19438875 0.1983968\n",
      " 0.20240486 0.20641279 0.21042085 0.2144289  0.21843684 0.22244489\n",
      " 0.22645295 0.23046088 0.23446894 0.23847699 0.24248493 0.24649298\n",
      " 0.25050104 0.2545091  0.25851703 0.26252508 0.26653314 0.27054107\n",
      " 0.27454913 0.27855718 0.28256512 0.28657317 0.29058123 0.29458916\n",
      " 0.29859722 0.30260527 0.3066132  0.31062126 0.31462932 0.31863725\n",
      " 0.3226453  0.32665336 0.3306613  0.33466935 0.3386774  0.34268534\n",
      " 0.3466934  0.35070145 0.3547094  0.35871744 0.3627255  0.36673343\n",
      " 0.3707415  0.37474954 0.37875748 0.38276553 0.3867736  0.39078152\n",
      " 0.39478958 0.39879763 0.4028057  0.40681362 0.41082168 0.41482973\n",
      " 0.41883767 0.42284572 0.42685378 0.4308617  0.43486977 0.43887782\n",
      " 0.44288576 0.4468938  0.45090187 0.4549098  0.45891786 0.4629259\n",
      " 0.46693385 0.4709419  0.47494996 0.4789579  0.48296595 0.486974\n",
      " 0.49098194 0.49499    0.49899805 0.503006   0.50701404 0.5110221\n",
      " 0.51503    0.5190381  0.52304614 0.5270541  0.5310621  0.5350702\n",
      " 0.53907824 0.5430862  0.5470942  0.5511023  0.5551102  0.5591183\n",
      " 0.5631263  0.56713426 0.5711423  0.5751504  0.5791583  0.58316636\n",
      " 0.5871744  0.59118235 0.5951904  0.59919846 0.6032064  0.60721445\n",
      " 0.6112225  0.61523044 0.6192385  0.62324655 0.6272545  0.63126254\n",
      " 0.6352706  0.63927853 0.6432866  0.64729464 0.6513026  0.65531063\n",
      " 0.6593187  0.6633266  0.6673347  0.67134273 0.67535067 0.6793587\n",
      " 0.6833668  0.68737483 0.69138277 0.6953908  0.6993989  0.7034068\n",
      " 0.70741487 0.7114229  0.71543086 0.7194389  0.72344697 0.7274549\n",
      " 0.73146296 0.735471   0.73947895 0.743487   0.74749506 0.751503\n",
      " 0.75551105 0.7595191  0.76352704 0.7675351  0.77154315 0.7755511\n",
      " 0.77955914 0.7835672  0.7875751  0.7915832  0.79559124 0.7995992\n",
      " 0.8036072  0.8076153  0.8116232  0.8156313  0.8196393  0.82364726\n",
      " 0.8276553  0.83166337 0.8356714  0.83967936 0.8436874  0.84769547\n",
      " 0.8517034  0.85571146 0.8597195  0.86372745 0.8677355  0.87174356\n",
      " 0.8757515  0.87975955 0.8837676  0.88777554 0.8917836  0.89579165\n",
      " 0.8997996  0.90380764 0.9078157  0.91182363 0.9158317  0.91983974\n",
      " 0.9238477  0.92785573 0.9318638  0.9358717  0.9398798  0.9438878\n",
      " 0.94789577 0.9519038  0.9559119  0.9599198  0.96392787 0.9679359\n",
      " 0.97194386 0.9759519  0.97995996 0.983968   0.98797596 0.991984\n",
      " 0.99599206 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(l1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Huber\n",
    "\n",
    "$$PH(y_r,y_p) = \\delta^2 \\cdot \\sqrt{1+\\left(\\frac{y_r-y_p}{\\delta}\\right)^2}-1, \\delta > 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1.+tf.square((target-x_vals)/delta1))-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2514441  0.25047213 0.2495004  0.24852893 0.24755764 0.24658659\n",
      " 0.24561578 0.24464527 0.24367496 0.2427049  0.24173515 0.24076563\n",
      " 0.23979636 0.23882735 0.23785861 0.23689017 0.23592193 0.23495403\n",
      " 0.23398636 0.23301901 0.23205197 0.23108518 0.23011866 0.22915247\n",
      " 0.2281866  0.227221   0.22625573 0.22529078 0.22432612 0.22336179\n",
      " 0.22239776 0.2214341  0.22047074 0.21950775 0.21854503 0.21758276\n",
      " 0.21662077 0.21565916 0.2146979  0.213737   0.21277645 0.21181628\n",
      " 0.21085653 0.20989713 0.20893814 0.20797952 0.2070213  0.20606348\n",
      " 0.20510611 0.20414913 0.20319253 0.20223643 0.20128073 0.20032547\n",
      " 0.19937061 0.19841626 0.19746235 0.19650891 0.19555594 0.19460341\n",
      " 0.19365141 0.1926999  0.19174886 0.19079834 0.18984833 0.18889885\n",
      " 0.18794988 0.18700147 0.18605357 0.18510623 0.1841595  0.18321328\n",
      " 0.18226765 0.1813226  0.18037817 0.17943433 0.17849112 0.17754848\n",
      " 0.17660652 0.17566518 0.1747245  0.17378448 0.17284511 0.17190646\n",
      " 0.17096847 0.17003122 0.16909468 0.16815884 0.16722377 0.16628942\n",
      " 0.16535585 0.16442305 0.16349106 0.16255985 0.16162945 0.16069992\n",
      " 0.15977119 0.15884332 0.15791634 0.15699024 0.15606503 0.15514076\n",
      " 0.1542174  0.15329501 0.15237357 0.15145311 0.15053366 0.14961524\n",
      " 0.14869784 0.14778148 0.14686622 0.14595205 0.14503895 0.14412704\n",
      " 0.14321625 0.14230664 0.14139825 0.14049107 0.1395851  0.13868041\n",
      " 0.13777703 0.13687494 0.13597418 0.13507481 0.1341768  0.13328023\n",
      " 0.1323851  0.13149144 0.13059929 0.12970866 0.12881958 0.12793212\n",
      " 0.12704626 0.12616205 0.12527955 0.12439876 0.12351973 0.12264249\n",
      " 0.12176708 0.12089356 0.12002195 0.11915227 0.11828458 0.11741894\n",
      " 0.11655535 0.11569387 0.11483459 0.11397748 0.11312266 0.11227013\n",
      " 0.11141995 0.1105722  0.10972689 0.1088841  0.10804389 0.10720628\n",
      " 0.10637137 0.10553921 0.10470985 0.10388337 0.10305983 0.10223926\n",
      " 0.1014218  0.10060748 0.09979634 0.09898852 0.09818406 0.09738303\n",
      " 0.09658554 0.09579165 0.09500144 0.09421503 0.09343249 0.09265389\n",
      " 0.09187935 0.09110896 0.09034281 0.08958104 0.08882371 0.08807094\n",
      " 0.08732286 0.08657955 0.08584115 0.08510776 0.08437952 0.08365657\n",
      " 0.08293901 0.08222695 0.08152058 0.08082001 0.08012536 0.07943682\n",
      " 0.07875449 0.07807856 0.07740918 0.07674648 0.07609066 0.07544185\n",
      " 0.07480022 0.07416598 0.07353928 0.0729203  0.07230922 0.07170624\n",
      " 0.07111152 0.07052529 0.06994771 0.06937901 0.06881936 0.068269\n",
      " 0.0677281  0.0671969  0.06667558 0.06616439 0.06566352 0.06517321\n",
      " 0.06469365 0.06422509 0.0637677  0.06332178 0.06288748 0.06246505\n",
      " 0.06205471 0.06165668 0.06127116 0.0608984  0.06053858 0.06019194\n",
      " 0.05985866 0.05953895 0.05923301 0.05894104 0.05866323 0.05839976\n",
      " 0.05815081 0.05791652 0.05769709 0.05749266 0.05730337 0.05712934\n",
      " 0.05697074 0.05682764 0.05670018 0.05658843 0.05649249 0.05641244\n",
      " 0.05634832 0.05630018 0.05626807 0.056252   0.056252   0.05626807\n",
      " 0.05630018 0.05634832 0.05641244 0.05649249 0.05658843 0.05670018\n",
      " 0.05682764 0.05697074 0.05712935 0.05730337 0.05749266 0.05769709\n",
      " 0.05791652 0.05815081 0.05839977 0.05866323 0.05894104 0.05923302\n",
      " 0.05953895 0.05985866 0.06019194 0.06053858 0.0608984  0.06127117\n",
      " 0.06165668 0.06205471 0.06246505 0.06288749 0.06332178 0.06376772\n",
      " 0.06422509 0.06469365 0.06517322 0.06566354 0.06616439 0.0666756\n",
      " 0.06719691 0.0677281  0.068269   0.06881937 0.06937901 0.06994771\n",
      " 0.07052529 0.07111152 0.07170624 0.07230923 0.0729203  0.07353928\n",
      " 0.074166   0.07480022 0.07544185 0.07609066 0.07674648 0.07740918\n",
      " 0.07807858 0.07875449 0.07943682 0.08012538 0.08081999 0.08152058\n",
      " 0.08222696 0.08293901 0.08365657 0.08437954 0.08510777 0.08584115\n",
      " 0.08657955 0.08732286 0.08807094 0.08882371 0.08958106 0.09034281\n",
      " 0.09110897 0.09187936 0.09265389 0.09343249 0.09421504 0.09500144\n",
      " 0.09579165 0.09658554 0.09738303 0.09818406 0.09898854 0.09979634\n",
      " 0.10060748 0.10142181 0.10223926 0.10305983 0.10388339 0.10470985\n",
      " 0.10553921 0.10637139 0.10720626 0.10804389 0.10888411 0.10972687\n",
      " 0.1105722  0.11141997 0.11227015 0.11312266 0.11397751 0.1148346\n",
      " 0.11569387 0.11655536 0.11741895 0.11828458 0.11915229 0.12002195\n",
      " 0.12089356 0.1217671  0.12264251 0.12351973 0.12439876 0.12527956\n",
      " 0.12616205 0.12704626 0.12793212 0.12881958 0.12970866 0.1305993\n",
      " 0.13149144 0.1323851  0.13328026 0.1341768  0.13507481 0.1359742\n",
      " 0.13687494 0.13777703 0.13868044 0.1395851  0.14049107 0.14139827\n",
      " 0.14230667 0.14321625 0.14412704 0.14503898 0.14595205 0.14686622\n",
      " 0.1477815  0.14869784 0.14961524 0.15053368 0.15145311 0.15237357\n",
      " 0.15329501 0.1542174  0.15514076 0.15606505 0.15699024 0.15791634\n",
      " 0.15884334 0.15977119 0.16069992 0.16162947 0.16255985 0.16349106\n",
      " 0.16442308 0.16535585 0.16628942 0.16722377 0.16815884 0.16909468\n",
      " 0.17003122 0.17096847 0.17190646 0.17284513 0.17378448 0.1747245\n",
      " 0.17566518 0.17660654 0.17754848 0.17849112 0.17943434 0.18037817\n",
      " 0.1813226  0.18226768 0.18321328 0.1841595  0.18510626 0.18605357\n",
      " 0.18700147 0.18794988 0.18889885 0.18984833 0.19079834 0.19174886\n",
      " 0.1926999  0.19365142 0.19460341 0.19555594 0.19650891 0.19746235\n",
      " 0.19841626 0.19937065 0.20032547 0.20128073 0.20223641 0.20319253\n",
      " 0.20414913 0.20510612 0.20606348 0.2070213  0.20797954 0.20893814\n",
      " 0.20989713 0.21085656 0.21181631 0.21277645 0.21373701 0.21469791\n",
      " 0.21565916 0.21662079 0.21758276 0.21854503 0.21950775 0.22047074\n",
      " 0.2214341  0.22239776 0.22336179 0.22432612 0.22529078 0.22625574\n",
      " 0.227221   0.2281866  0.22915252 0.23011866 0.23108518 0.23205197\n",
      " 0.23301901 0.23398636 0.23495401 0.23592193 0.23689017 0.23785861\n",
      " 0.23882735 0.23979636 0.24076563 0.24173515 0.2427049  0.24367496\n",
      " 0.24464524 0.24561578 0.24658659 0.24755764 0.2485289  0.2495004\n",
      " 0.25047216 0.2514441 ]\n"
     ]
    }
   ],
   "source": [
    "phuber1_y_out = session.run(phuber1_y_vals)\n",
    "print(phuber1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida para problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-3.,5.,500)\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([500,],1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge (función bisagra)\n",
    "\n",
    "$$H(y_r,y_p)=max(0, 1-y_r\\cdot y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.         3.983968   3.9679358  3.9519038  3.9358718  3.9198396\n",
      " 3.9038076  3.8877757  3.8717434  3.8557115  3.8396792  3.8236473\n",
      " 3.8076153  3.791583   3.775551   3.759519   3.743487   3.727455\n",
      " 3.711423   3.6953907  3.6793587  3.6633267  3.6472945  3.6312625\n",
      " 3.6152306  3.5991983  3.5831664  3.5671344  3.5511022  3.5350702\n",
      " 3.5190382  3.503006   3.486974   3.470942   3.4549098  3.4388778\n",
      " 3.4228456  3.4068136  3.3907816  3.3747494  3.3587174  3.3426852\n",
      " 3.3266532  3.3106213  3.294589   3.278557   3.262525   3.2464929\n",
      " 3.230461   3.214429   3.1983967  3.1823647  3.1663327  3.1503005\n",
      " 3.1342685  3.1182365  3.1022043  3.0861723  3.0701404  3.0541081\n",
      " 3.0380762  3.0220442  3.006012   2.98998    2.973948   2.9579158\n",
      " 2.9418838  2.9258518  2.9098196  2.8937874  2.8777556  2.8617234\n",
      " 2.8456912  2.8296595  2.8136272  2.797595   2.7815633  2.765531\n",
      " 2.7494988  2.7334669  2.717435   2.7014027  2.6853707  2.6693387\n",
      " 2.6533065  2.6372745  2.6212425  2.6052103  2.5891783  2.5731463\n",
      " 2.5571141  2.5410821  2.5250502  2.509018   2.492986   2.476954\n",
      " 2.4609218  2.4448898  2.4288578  2.4128256  2.3967936  2.3807616\n",
      " 2.3647294  2.3486974  2.3326654  2.3166332  2.300601   2.2845693\n",
      " 2.268537   2.2525048  2.236473   2.2204409  2.2044086  2.188377\n",
      " 2.1723447  2.1563125  2.1402805  2.1242485  2.1082163  2.0921843\n",
      " 2.0761523  2.06012    2.0440881  2.0280561  2.012024   1.995992\n",
      " 1.97996    1.9639277  1.9478958  1.9318638  1.9158316  1.8997996\n",
      " 1.8837676  1.8677354  1.8517034  1.8356714  1.8196392  1.8036072\n",
      " 1.787575   1.771543   1.755511   1.7394788  1.7234468  1.7074149\n",
      " 1.6913826  1.6753507  1.6593187  1.6432865  1.6272545  1.6112225\n",
      " 1.5951903  1.5791583  1.5631263  1.5470941  1.5310621  1.5150301\n",
      " 1.4989979  1.482966   1.4669337  1.4509017  1.4348698  1.4188375\n",
      " 1.4028056  1.3867736  1.3707414  1.3547094  1.3386774  1.3226452\n",
      " 1.3066132  1.2905812  1.274549   1.258517   1.242485   1.2264528\n",
      " 1.2104208  1.1943886  1.1783566  1.1623247  1.1462924  1.1302605\n",
      " 1.1142285  1.0981963  1.0821643  1.0661323  1.0501001  1.0340681\n",
      " 1.0180361  1.0020039  0.9859719  0.96993995 0.9539077  0.93787575\n",
      " 0.9218435  0.90581155 0.88977957 0.87374735 0.85771537 0.8416834\n",
      " 0.82565117 0.8096192  0.7935872  0.777555   0.761523   0.745491\n",
      " 0.7294588  0.7134268  0.69739485 0.6813626  0.66533065 0.64929867\n",
      " 0.63326645 0.61723447 0.60120225 0.58517027 0.5691383  0.55310607\n",
      " 0.5370741  0.5210421  0.5050099  0.4889779  0.47294593 0.4569137\n",
      " 0.44088173 0.42484975 0.40881753 0.39278555 0.37675357 0.36072135\n",
      " 0.34468937 0.32865715 0.31262517 0.2965932  0.28056097 0.264529\n",
      " 0.24849701 0.23246479 0.21643281 0.20040083 0.18436861 0.16833663\n",
      " 0.15230465 0.13627243 0.12024045 0.10420847 0.08817625 0.07214427\n",
      " 0.05611229 0.04008007 0.02404809 0.00801587 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "hinge_y_vals = tf.maximum(0., 1.0 - tf.multiply(target, x_vals))\n",
    "hinge_y_out = session.run(hinge_y_vals)\n",
    "print(hinge_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada (función logística)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log(y_p) - (1-y_r)\\cdot log(1-y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 4.266695   3.504558   3.07711    2.7786188\n",
      " 2.5490425  2.3624578  2.205273   2.0694702  1.9499258  1.8431584\n",
      " 1.7466972  1.658729   1.5778773  1.5030754  1.4334824  1.3684192\n",
      " 1.307331   1.2497613  1.1953264  1.1437016  1.0946122  1.0478203\n",
      " 1.0031197  0.96033263 0.9193009  0.8798871  0.8419681  0.805434\n",
      " 0.7701883  0.7361426  0.7032175  0.67134243 0.64045215 0.61048704\n",
      " 0.58139426 0.55312395 0.5256306  0.49887323 0.4728133  0.44741485\n",
      " 0.4226459  0.39847532 0.37487555 0.35181987 0.3292835  0.30724418\n",
      " 0.2856801  0.26457092 0.24389847 0.2236447  0.20379275 0.18432751\n",
      " 0.16523395 0.14649788 0.12810664 0.11004756 0.09230857 0.07487902\n",
      " 0.05774807 0.0409054  0.02434197 0.00804817        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    }
   ],
   "source": [
    "xentr_y_vals = -tf.multiply(target, tf.log(x_vals)) - tf.multiply((1.-target), tf.log(1.-x_vals))\n",
    "xentr_y_out = session.run(xentr_y_vals)\n",
    "print(xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada de sigmoide (evitar nans)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log\\left(\\frac{1}{1+e^{-y_p}}\\right) - (1-y_r)\\cdot log\\left(1-\\frac{1}{1+e^{-y_p}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0485873  3.0333216  3.0180674  3.0028253  2.9875953  2.9723773\n",
      " 2.9571722  2.9419796  2.9267998  2.9116333  2.8964796  2.8813396\n",
      " 2.866213   2.8511002  2.8360016  2.8209174  2.805847   2.7907915\n",
      " 2.7757509  2.7607253  2.7457147  2.7307198  2.7157404  2.700777\n",
      " 2.6858296  2.6708984  2.6559842  2.6410863  2.6262057  2.6113422\n",
      " 2.5964963  2.581668   2.5668578  2.5520658  2.5372922  2.5225375\n",
      " 2.5078013  2.493085   2.4783878  2.4637103  2.4490528  2.4344156\n",
      " 2.419799   2.4052036  2.3906288  2.3760755  2.3615441  2.3470345\n",
      " 2.332547   2.3180823  2.3036401  2.2892213  2.2748258  2.2604537\n",
      " 2.246106   2.2317827  2.2174835  2.2032096  2.188961   2.174738\n",
      " 2.1605408  2.14637    2.1322253  2.1181078  2.1040173  2.0899544\n",
      " 2.0759194  2.0619125  2.0479343  2.0339847  2.0200646  2.006174\n",
      " 1.9923133  1.978483   1.964683   1.9509143  1.9371768  1.923471\n",
      " 1.9097973  1.8961561  1.8825476  1.8689723  1.8554305  1.8419226\n",
      " 1.828449   1.8150101  1.8016063  1.7882378  1.7749051  1.7616086\n",
      " 1.7483487  1.7351258  1.7219402  1.7087922  1.6956824  1.6826111\n",
      " 1.6695787  1.6565857  1.6436323  1.630719   1.6178461  1.6050141\n",
      " 1.5922233  1.5794743  1.5667672  1.5541027  1.5414809  1.5289024\n",
      " 1.5163676  1.5038767  1.4914304  1.4790288  1.4666724  1.4543618\n",
      " 1.4420971  1.4298787  1.4177072  1.4055829  1.393506   1.3814772\n",
      " 1.3694968  1.357565   1.3456825  1.3338494  1.3220662  1.3103331\n",
      " 1.2986509  1.2870194  1.2754395  1.2639112  1.252435   1.2410114\n",
      " 1.2296406  1.2183228  1.2070587  1.1958485  1.1846924  1.1735909\n",
      " 1.1625443  1.1515529  1.1406174  1.1297374  1.1189138  1.1081467\n",
      " 1.0974362  1.0867832  1.0761876  1.0656495  1.0551697  1.0447482\n",
      " 1.0343852  1.0240812  1.0138364  1.0036507  0.993525   0.9834591\n",
      " 0.97345334 0.9635081  0.9536234  0.94379973 0.9340371  0.92433566\n",
      " 0.9146959  0.9051178  0.8956015  0.8861475  0.87675565 0.8674262\n",
      " 0.8581595  0.8489556  0.83981436 0.83073646 0.8217216  0.81277007\n",
      " 0.803882   0.7950575  0.7862966  0.7775996  0.7689662  0.7603969\n",
      " 0.75189155 0.7434501  0.735073   0.7267599  0.7185109  0.7103263\n",
      " 0.7022059  0.6941497  0.6861577  0.67823017 0.6703666  0.66256744\n",
      " 0.6548323  0.64716154 0.63955474 0.632012   0.62453336 0.61711866\n",
      " 0.6097677  0.6024806  0.5952571  0.5880972  0.5810008  0.5739678\n",
      " 0.5669979  0.5600912  0.5532474  0.54646635 0.5397481  0.5330923\n",
      " 0.5264987  0.51996744 0.51349795 0.5070903  0.5007442  0.49445942\n",
      " 0.48823592 0.48207334 0.47597137 0.46992996 0.46394876 0.45802754\n",
      " 0.45216608 0.44636413 0.4406213  0.43493748 0.4293124  0.4237456\n",
      " 0.418237   0.4127862  0.40739292 0.4020569  0.39677775 0.39155528\n",
      " 0.38638905 0.38127875 0.3762242  0.37122494 0.36628062 0.361391\n",
      " 0.35655573 0.35177428 0.3470466  0.34237215 0.33775058 0.33318156\n",
      " 0.3286648  0.32419977 0.31978628 0.3154238  0.31111214 0.30685073\n",
      " 0.30263945 0.2984776  0.294365   0.2903013  0.28628597 0.28231865\n",
      " 0.27839914 0.27452683 0.27070138 0.26692253 0.2631897  0.25950256\n",
      " 0.25586087 0.252264   0.24871165 0.24520354 0.24173906 0.2383179\n",
      " 0.23493983 0.23160417 0.22831067 0.22505905 0.22184868 0.21867928\n",
      " 0.21555042 0.21246186 0.20941298 0.20640348 0.20343307 0.20050117\n",
      " 0.19760749 0.19475172 0.19193329 0.18915193 0.18640728 0.18369885\n",
      " 0.1810263  0.17838936 0.17578746 0.17322034 0.17068763 0.16818888\n",
      " 0.16572374 0.16329196 0.16089298 0.15852652 0.15619229 0.15388978\n",
      " 0.1516187  0.14937878 0.14716949 0.14499056 0.1428417  0.14072245\n",
      " 0.13863249 0.1365716  0.13453922 0.13253517 0.13055909 0.12861057\n",
      " 0.12668931 0.12479503 0.1229274  0.12108601 0.11927059 0.11748087\n",
      " 0.11571644 0.11397702 0.11226235 0.11057204 0.1089058  0.1072634\n",
      " 0.10564445 0.10404868 0.10247584 0.10092555 0.09939756 0.09789165\n",
      " 0.09640741 0.09494463 0.09350307 0.09208237 0.09068228 0.08930258\n",
      " 0.08794292 0.08660308 0.08528284 0.08398185 0.0826999  0.08143677\n",
      " 0.08019212 0.07896577 0.07775748 0.07656694 0.07539396 0.07423832\n",
      " 0.07309971 0.07197795 0.07087281 0.06978408 0.06871147 0.0676548\n",
      " 0.06661386 0.06558841 0.06457823 0.06358314 0.06260289 0.06163729\n",
      " 0.06068617 0.05974926 0.05882638 0.05791738 0.05702201 0.05614009\n",
      " 0.05527147 0.0544159  0.05357321 0.05274327 0.05192582 0.05112073\n",
      " 0.05032782 0.04954689 0.04877779 0.04802036 0.04727439 0.04653975\n",
      " 0.04581628 0.04510379 0.04440213 0.04371117 0.04303072 0.04236063\n",
      " 0.04170077 0.04105099 0.04041111 0.03978101 0.03916057 0.03854959\n",
      " 0.03794797 0.03735558 0.03677225 0.03619787 0.03563231 0.03507543\n",
      " 0.0345271  0.0339872  0.0334556  0.03293218 0.03241682 0.03190939\n",
      " 0.03140978 0.03091788 0.03043356 0.02995671 0.02948724 0.029025\n",
      " 0.02856991 0.02812186 0.02768073 0.02724643 0.02681887 0.02639791\n",
      " 0.02598347 0.02557547 0.02517379 0.02477833 0.02438902 0.02400575\n",
      " 0.02362843 0.02325697 0.0228913  0.0225313  0.02217689 0.02182801\n",
      " 0.02148456 0.02114644 0.02081361 0.02048595 0.02016339 0.01984588\n",
      " 0.0195333  0.0192256  0.01892272 0.01862455 0.01833104 0.01804211\n",
      " 0.0177577  0.01747772 0.01720214 0.01693085 0.01666381 0.01640095\n",
      " 0.0161422  0.0158875  0.01563678 0.01539    0.01514707 0.01490796\n",
      " 0.01467259 0.01444091 0.01421286 0.01398839 0.01376744 0.01354996\n",
      " 0.01333589 0.01312517 0.01291777 0.01271363 0.01251268 0.0123149\n",
      " 0.01212022 0.0119286  0.01174    0.01155436 0.01137163 0.01119178\n",
      " 0.01101477 0.01084053 0.01066904 0.01050024 0.0103341  0.01017058\n",
      " 0.01000963 0.00985122 0.0096953  0.00954184 0.00939079 0.00924212\n",
      " 0.0090958  0.00895179 0.00881004 0.00867053 0.00853322 0.00839807\n",
      " 0.00826506 0.00813414 0.00800529 0.00787847 0.00775366 0.00763081\n",
      " 0.0075099  0.0073909  0.00727378 0.00715851 0.00704506 0.0069334\n",
      " 0.00682351 0.00671535]\n"
     ]
    }
   ],
   "source": [
    "xentr_sig_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_vals, labels = targets)\n",
    "xentr_sig_y_out = session.run(xentr_sig_y_vals)\n",
    "print(xentr_sig_y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5242937  1.5166608  1.5090337  1.5014126  1.4937977  1.4861887\n",
      " 1.4785861  1.4709898  1.4633999  1.4558166  1.4482398  1.4406698\n",
      " 1.4331065  1.4255501  1.4180008  1.4104587  1.4029235  1.3953958\n",
      " 1.3878754  1.3803626  1.3728573  1.3653599  1.3578702  1.3503885\n",
      " 1.3429148  1.3354492  1.3279921  1.3205432  1.3131028  1.3056711\n",
      " 1.2982482  1.290834   1.2834289  1.2760329  1.2686461  1.2612687\n",
      " 1.2539006  1.2465425  1.2391939  1.2318552  1.2245264  1.2172078\n",
      " 1.2098995  1.2026018  1.1953144  1.1880378  1.1807721  1.1735172\n",
      " 1.1662735  1.1590412  1.1518201  1.1446106  1.1374129  1.1302269\n",
      " 1.123053   1.1158913  1.1087418  1.1016048  1.0944805  1.087369\n",
      " 1.0802704  1.073185   1.0661126  1.0590539  1.0520086  1.0449772\n",
      " 1.0379597  1.0309563  1.0239671  1.0169923  1.0100323  1.003087\n",
      " 0.99615663 0.9892415  0.9823415  0.97545713 0.9685884  0.9617355\n",
      " 0.95489866 0.94807804 0.9412738  0.93448615 0.92771524 0.9209613\n",
      " 0.9142245  0.90750504 0.90080315 0.8941189  0.88745254 0.8808043\n",
      " 0.87417436 0.8675629  0.8609701  0.8543961  0.8478412  0.84130555\n",
      " 0.83478934 0.82829285 0.82181615 0.8153595  0.80892307 0.80250704\n",
      " 0.79611164 0.78973716 0.7833836  0.7770513  0.77074045 0.7644512\n",
      " 0.7581838  0.75193834 0.7457152  0.7395144  0.7333362  0.7271809\n",
      " 0.72104853 0.71493936 0.7088536  0.70279145 0.696753   0.6907386\n",
      " 0.6847484  0.6787825  0.67284125 0.6669247  0.6610331  0.65516657\n",
      " 0.64932543 0.6435097  0.63771975 0.6319556  0.6262175  0.6205057\n",
      " 0.6148203  0.6091614  0.60352933 0.59792423 0.5923462  0.58679545\n",
      " 0.5812721  0.57577646 0.5703087  0.5648687  0.5594569  0.55407333\n",
      " 0.5487181  0.5433916  0.5380938  0.53282475 0.52758485 0.5223741\n",
      " 0.5171926  0.5120406  0.5069182  0.50182533 0.4967625  0.49172956\n",
      " 0.48672667 0.48175406 0.4768117  0.47189987 0.46701854 0.46216783\n",
      " 0.45734796 0.4525589  0.44780076 0.44307375 0.43837783 0.4337131\n",
      " 0.42907974 0.4244778  0.41990718 0.41536823 0.4108608  0.40638503\n",
      " 0.401941   0.39752874 0.3931483  0.3887998  0.3844831  0.38019845\n",
      " 0.37594578 0.37172505 0.3675365  0.36337996 0.35925546 0.35516316\n",
      " 0.35110295 0.34707484 0.34307885 0.33911508 0.3351833  0.33128372\n",
      " 0.32741615 0.32358077 0.31977737 0.316006   0.31226668 0.30855933\n",
      " 0.30488384 0.3012403  0.29762855 0.2940486  0.2905004  0.2869839\n",
      " 0.28349894 0.2800456  0.2766237  0.27323318 0.26987404 0.26654616\n",
      " 0.26324934 0.25998372 0.25674897 0.25354514 0.2503721  0.24722971\n",
      " 0.24411796 0.24103667 0.23798569 0.23496498 0.23197438 0.22901377\n",
      " 0.22608304 0.22318207 0.22031064 0.21746874 0.2146562  0.2118728\n",
      " 0.2091185  0.2063931  0.20369646 0.20102845 0.19838887 0.19577764\n",
      " 0.19319452 0.19063938 0.1881121  0.18561247 0.18314031 0.1806955\n",
      " 0.17827787 0.17588714 0.1735233  0.17118607 0.16887529 0.16659078\n",
      " 0.1643324  0.16209988 0.15989314 0.1577119  0.15555607 0.15342537\n",
      " 0.15131973 0.1492388  0.1471825  0.14515065 0.14314298 0.14115933\n",
      " 0.13919957 0.13726342 0.13535069 0.13346127 0.13159485 0.12975128\n",
      " 0.12793043 0.126132   0.12435582 0.12260177 0.12086953 0.11915895\n",
      " 0.11746991 0.11580209 0.11415534 0.11252952 0.11092434 0.10933964\n",
      " 0.10777521 0.10623093 0.10470649 0.10320174 0.10171653 0.10025059\n",
      " 0.09880374 0.09737586 0.09596664 0.09457596 0.09320364 0.09184942\n",
      " 0.09051315 0.08919468 0.08789373 0.08661017 0.08534382 0.08409444\n",
      " 0.08286187 0.08164598 0.08044649 0.07926326 0.07809614 0.07694489\n",
      " 0.07580935 0.07468939 0.07358474 0.07249528 0.07142085 0.07036123\n",
      " 0.06931625 0.0682858  0.06726961 0.06626759 0.06527954 0.06430528\n",
      " 0.06334466 0.06239751 0.0614637  0.060543   0.0596353  0.05874044\n",
      " 0.05785822 0.05698851 0.05613118 0.05528602 0.0544529  0.0536317\n",
      " 0.05282222 0.05202434 0.05123792 0.05046277 0.04969878 0.04894583\n",
      " 0.04820371 0.04747232 0.04675154 0.04604118 0.04534114 0.04465129\n",
      " 0.04397146 0.04330154 0.04264142 0.04199092 0.04134995 0.04071838\n",
      " 0.04009606 0.03948288 0.03887874 0.03828347 0.03769698 0.03711916\n",
      " 0.03654986 0.03598898 0.0354364  0.03489204 0.03435573 0.0338274\n",
      " 0.03330693 0.0327942  0.03228911 0.03179157 0.03130144 0.03081865\n",
      " 0.03034308 0.02987463 0.02941319 0.02895869 0.02851101 0.02807005\n",
      " 0.02763574 0.02720795 0.02678661 0.02637164 0.02596291 0.02556036\n",
      " 0.02516391 0.02477345 0.0243889  0.02401018 0.0236372  0.02326987\n",
      " 0.02290814 0.0225519  0.02220107 0.02185559 0.02151536 0.02118032\n",
      " 0.02085038 0.02052549 0.02020556 0.01989051 0.01958028 0.0192748\n",
      " 0.01897398 0.01867779 0.01838612 0.01809894 0.01781616 0.01753771\n",
      " 0.01726355 0.0169936  0.0167278  0.01646609 0.01620841 0.0159547\n",
      " 0.01570489 0.01545894 0.01521678 0.01497835 0.01474362 0.0145125\n",
      " 0.01428495 0.01406093 0.01384037 0.01362322 0.01340943 0.01319895\n",
      " 0.01299174 0.01278774 0.01258689 0.01238917 0.01219451 0.01200288\n",
      " 0.01181422 0.01162849 0.01144565 0.01126565 0.01108845 0.01091401\n",
      " 0.01074228 0.01057322 0.0104068  0.01024297 0.0100817  0.00992294\n",
      " 0.00976665 0.0096128  0.00946136 0.00931227 0.00916552 0.00902106\n",
      " 0.00887885 0.00873886 0.00860107 0.00846543 0.00833191 0.00820047\n",
      " 0.0080711  0.00794375 0.00781839 0.007695   0.00757354 0.00745398\n",
      " 0.00733629 0.00722045 0.00710643 0.0069942  0.00688372 0.00677498\n",
      " 0.00666794 0.00656259 0.00645888 0.00635681 0.00625634 0.00615745\n",
      " 0.00606011 0.0059643  0.00587    0.00577718 0.00568582 0.00559589\n",
      " 0.00550738 0.00542026 0.00533452 0.00525012 0.00516705 0.00508529\n",
      " 0.00500482 0.00492561 0.00484765 0.00477092 0.0046954  0.00462106\n",
      " 0.0045479  0.00447589 0.00440502 0.00433527 0.00426661 0.00419904\n",
      " 0.00413253 0.00406707 0.00400264 0.00393924 0.00387683 0.0038154\n",
      " 0.00375495 0.00369545 0.00363689 0.00357925 0.00352253 0.0034667\n",
      " 0.00341175 0.00335767]\n"
     ]
    }
   ],
   "source": [
    "pos_weight = tf.constant(0.5)\n",
    "xentr_sig_w_y_vals = tf.nn.weighted_cross_entropy_with_logits(logits=x_vals, targets = targets, pos_weight = pos_weight)\n",
    "xentr_sig_w_y_out = session.run(xentr_sig_w_y_vals)\n",
    "print(xentr_sig_w_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Cross Entropy (probabilidad)\n",
    "\n",
    "$$SM(z_k) = \\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1601256]\n"
     ]
    }
   ],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[0.1,0.02,0.88]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse softmax cross entropy (vector 0s y un 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[2]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar las funciones de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_array = session.run(x_vals)\n",
    "plt.plot(x_array, l2_y_out, 'r-', label='L2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
