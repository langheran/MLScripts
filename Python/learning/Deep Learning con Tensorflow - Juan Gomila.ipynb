{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Con Tensorflow\n",
    "\n",
    "Tomado del curso [Deep Learning con Tensorflow para Machine Learning e IA](https://www.udemy.com/course/tensorflow-python/) del profesor [Juan Gabriel Gomila Salas](https://github.com/joanby/tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones en el grafo de computación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.array([2.,4.,6.,8.,10.,12.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m_const = tf.constant(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ y = mx = 3x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_1:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_product = tf.multiply(m_const, x_data)\n",
    "my_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "12.0\n",
      "18.0\n",
      "24.0\n",
      "30.0\n",
      "36.0\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(my_product, feed_dict = {x_data: x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 12. 18. 24. 30. 36.]\n"
     ]
    }
   ],
   "source": [
    "print(session.run(my_product, feed_dict = {x_data: x_vals}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6., 12., 18., 24., 30., 36.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.multiply(m_const, x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operaciones por capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  5.,  7.],\n",
       "       [-2.,  0.,  7.,  6.],\n",
       "       [-6., -1.,  0.,  3.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array = np.array([[1.,3.,5.,7.],\n",
    "                    [-2.,0.,7.,6.],\n",
    "                    [-6.,-1.,0.,3.]])\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  3.,  5.,  7.],\n",
       "        [-2.,  0.,  7.,  6.],\n",
       "        [-6., -1.,  0.,  3.]],\n",
       "\n",
       "       [[ 2.,  4.,  6.,  8.],\n",
       "        [-1.,  1.,  8.,  7.],\n",
       "        [-5.,  0.,  1.,  4.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals = np.array([my_array, my_array+1])\n",
    "x_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=(3,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m1 = tf.constant([[1.],[0.],[-2.],[5.]])\n",
    "m2 = tf.constant([[7.]])\n",
    "a1 = tf.constant([[15.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$(X\\cdot m_1)m_2+a_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prod1 = tf.matmul(x_data, m1)\n",
    "prod2 = tf.matmul(prod1, m2)\n",
    "add1 = tf.add(prod2, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197.]\n",
      " [113.]\n",
      " [ 78.]]\n",
      "[[225.]\n",
      " [141.]\n",
      " [106.]]\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(session.run(add1, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Trabajar con múltiples capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "session = tf.InteractiveSession()\n",
    "# session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.06128026],\n",
       "         [0.87156032],\n",
       "         [0.72401941],\n",
       "         [0.60112092]],\n",
       "\n",
       "        [[0.8891606 ],\n",
       "         [0.28728361],\n",
       "         [0.83489501],\n",
       "         [0.40807198]],\n",
       "\n",
       "        [[0.7320763 ],\n",
       "         [0.75241017],\n",
       "         [0.79797285],\n",
       "         [0.77101396]],\n",
       "\n",
       "        [[0.76440585],\n",
       "         [0.00251679],\n",
       "         [0.54689621],\n",
       "         [0.13860781]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape = [1,4,4,1]\n",
    "x_val = np.random.uniform(size = x_shape)\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape = x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_filter = tf.constant(0.25, shape = [2,2,1,1])\n",
    "my_strides = [1,2,2,1]\n",
    "mov_avg_layer = tf.nn.conv2d(x_data, my_filter,my_strides, padding='SAME', name='Moving_Average_Wnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\\frac{W-F+2P}{S}+1$$\n",
    "\n",
    "- W : dimensión de entrada\n",
    "- F: Dimensión del filtro\n",
    "- P: Padding\n",
    "- S: Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_layer(input_matrix):\n",
    "    input_matrix_squeezed  =tf.squeeze(input_matrix)\n",
    "    A = tf.constant([[1.,2.],[3.,4.]])\n",
    "    b = tf.constant(1., shape=[2,2])\n",
    "    temp1 = tf.matmul(A, input_matrix_squeezed)\n",
    "    temp2 = tf.add(temp1, b)\n",
    "    return tf.sigmoid(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Custom_layer\") as scope:\n",
    "    customlayer1 = custom_layer(mov_avg_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9341972 , 0.94099253],\n",
       "       [0.9921033 , 0.9944067 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(customlayer1, feed_dict={x_data: x_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('multiple-layes', session.graph)\n",
    "session.run(customlayer1, feed_dict={x_data: x_val})\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida en predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-1.,1.,500)\n",
    "target = tf.constant(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L2 (distancia Euclidiana)\n",
    "\n",
    "$$L2(y_r, y_p) = \\sqrt{\\sum(y_r-y_p)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_y_vals = tf.square(target-x_vals)\n",
    "l2_y_out = session.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338.6773162148966\n"
     ]
    }
   ],
   "source": [
    "l2_y_vals = tf.sqrt(tf.reduce_sum(tf.square(target-x_vals)))\n",
    "l2_y_out = session.run(l2_y_vals)\n",
    "print((l2_y_out**2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.667336"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.nn.l2_loss(target-x_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norma L1\n",
    "\n",
    "$$L1(y_r,y_p)=|y_r-y_p|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_vals = tf.abs(target-x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_y_out = session.run(l1_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.995992   0.99198395 0.98797596 0.98396796 0.9799599\n",
      " 0.9759519  0.9719439  0.96793586 0.96392787 0.9599198  0.9559118\n",
      " 0.9519038  0.94789577 0.94388777 0.9398798  0.9358717  0.9318637\n",
      " 0.92785573 0.9238477  0.9198397  0.9158317  0.91182363 0.90781564\n",
      " 0.90380764 0.8997996  0.8957916  0.8917836  0.88777554 0.88376755\n",
      " 0.87975955 0.8757515  0.8717435  0.8677355  0.86372745 0.85971946\n",
      " 0.8557114  0.8517034  0.8476954  0.84368736 0.83967936 0.8356713\n",
      " 0.8316633  0.8276553  0.82364726 0.81963927 0.8156313  0.8116232\n",
      " 0.8076152  0.8036072  0.7995992  0.7955912  0.7915832  0.7875751\n",
      " 0.78356713 0.77955914 0.7755511  0.7715431  0.7675351  0.76352704\n",
      " 0.75951904 0.75551105 0.751503   0.747495   0.743487   0.73947895\n",
      " 0.73547095 0.73146296 0.7274549  0.72344685 0.7194389  0.71543086\n",
      " 0.7114228  0.70741487 0.7034068  0.69939876 0.6953908  0.69138277\n",
      " 0.6873747  0.6833667  0.6793587  0.67535067 0.6713427  0.6673347\n",
      " 0.6633266  0.6593186  0.65531063 0.6513026  0.6472946  0.6432866\n",
      " 0.63927853 0.63527054 0.63126254 0.6272545  0.6232465  0.6192385\n",
      " 0.61523044 0.61122245 0.60721445 0.6032064  0.5991984  0.5951904\n",
      " 0.59118235 0.58717436 0.58316636 0.5791583  0.57515025 0.5711423\n",
      " 0.56713426 0.5631262  0.5591183  0.5551102  0.55110216 0.5470942\n",
      " 0.5430862  0.5390781  0.5350701  0.5310621  0.5270541  0.5230461\n",
      " 0.5190381  0.51503    0.51102203 0.50701404 0.503006   0.498998\n",
      " 0.49499    0.49098194 0.48697394 0.48296595 0.4789579  0.4749499\n",
      " 0.4709419  0.46693385 0.46292585 0.45891786 0.4549098  0.4509018\n",
      " 0.44689375 0.44288576 0.43887776 0.4348697  0.4308617  0.42685372\n",
      " 0.42284566 0.41883767 0.41482967 0.41082162 0.40681362 0.40280563\n",
      " 0.39879757 0.39478958 0.39078158 0.38677353 0.38276553 0.37875754\n",
      " 0.37474948 0.3707415  0.36673343 0.36272544 0.35871744 0.3547094\n",
      " 0.3507014  0.3466934  0.34268534 0.33867735 0.33466935 0.3306613\n",
      " 0.3266533  0.3226453  0.31863725 0.31462926 0.31062126 0.3066132\n",
      " 0.3026052  0.29859716 0.29458916 0.29058117 0.2865731  0.28256512\n",
      " 0.27855712 0.27454907 0.27054107 0.26653308 0.26252502 0.25851703\n",
      " 0.25450903 0.25050098 0.24649298 0.24248499 0.23847693 0.23446894\n",
      " 0.23046088 0.22645289 0.22244489 0.21843684 0.21442884 0.21042085\n",
      " 0.20641279 0.2024048  0.1983968  0.19438875 0.19038075 0.18637276\n",
      " 0.1823647  0.1783567  0.17434871 0.17034066 0.16633266 0.16232467\n",
      " 0.15831661 0.15430862 0.15030056 0.14629257 0.14228457 0.13827652\n",
      " 0.13426852 0.13026053 0.12625247 0.12224448 0.11823648 0.11422843\n",
      " 0.11022043 0.10621244 0.10220438 0.09819639 0.09418839 0.09018034\n",
      " 0.08617234 0.08216429 0.07815629 0.0741483  0.07014024 0.06613225\n",
      " 0.06212425 0.0581162  0.0541082  0.05010021 0.04609215 0.04208416\n",
      " 0.03807616 0.03406811 0.03006011 0.02605212 0.02204406 0.01803607\n",
      " 0.01402807 0.01002002 0.00601202 0.00200397 0.00200403 0.00601208\n",
      " 0.01002002 0.01402807 0.01803613 0.02204406 0.02605212 0.03006017\n",
      " 0.03406811 0.03807616 0.04208422 0.04609215 0.05010021 0.05410826\n",
      " 0.0581162  0.06212425 0.06613231 0.07014024 0.0741483  0.07815635\n",
      " 0.08216429 0.08617234 0.0901804  0.09418833 0.09819639 0.10220444\n",
      " 0.1062125  0.11022043 0.11422849 0.11823654 0.12224448 0.12625253\n",
      " 0.13026059 0.13426852 0.13827658 0.14228463 0.14629257 0.15030062\n",
      " 0.15430868 0.15831661 0.16232467 0.16633272 0.17034066 0.17434871\n",
      " 0.17835677 0.1823647  0.18637276 0.19038081 0.19438875 0.1983968\n",
      " 0.20240486 0.20641279 0.21042085 0.2144289  0.21843684 0.22244489\n",
      " 0.22645295 0.23046088 0.23446894 0.23847699 0.24248493 0.24649298\n",
      " 0.25050104 0.2545091  0.25851703 0.26252508 0.26653314 0.27054107\n",
      " 0.27454913 0.27855718 0.28256512 0.28657317 0.29058123 0.29458916\n",
      " 0.29859722 0.30260527 0.3066132  0.31062126 0.31462932 0.31863725\n",
      " 0.3226453  0.32665336 0.3306613  0.33466935 0.3386774  0.34268534\n",
      " 0.3466934  0.35070145 0.3547094  0.35871744 0.3627255  0.36673343\n",
      " 0.3707415  0.37474954 0.37875748 0.38276553 0.3867736  0.39078152\n",
      " 0.39478958 0.39879763 0.4028057  0.40681362 0.41082168 0.41482973\n",
      " 0.41883767 0.42284572 0.42685378 0.4308617  0.43486977 0.43887782\n",
      " 0.44288576 0.4468938  0.45090187 0.4549098  0.45891786 0.4629259\n",
      " 0.46693385 0.4709419  0.47494996 0.4789579  0.48296595 0.486974\n",
      " 0.49098194 0.49499    0.49899805 0.503006   0.50701404 0.5110221\n",
      " 0.51503    0.5190381  0.52304614 0.5270541  0.5310621  0.5350702\n",
      " 0.53907824 0.5430862  0.5470942  0.5511023  0.5551102  0.5591183\n",
      " 0.5631263  0.56713426 0.5711423  0.5751504  0.5791583  0.58316636\n",
      " 0.5871744  0.59118235 0.5951904  0.59919846 0.6032064  0.60721445\n",
      " 0.6112225  0.61523044 0.6192385  0.62324655 0.6272545  0.63126254\n",
      " 0.6352706  0.63927853 0.6432866  0.64729464 0.6513026  0.65531063\n",
      " 0.6593187  0.6633266  0.6673347  0.67134273 0.67535067 0.6793587\n",
      " 0.6833668  0.68737483 0.69138277 0.6953908  0.6993989  0.7034068\n",
      " 0.70741487 0.7114229  0.71543086 0.7194389  0.72344697 0.7274549\n",
      " 0.73146296 0.735471   0.73947895 0.743487   0.74749506 0.751503\n",
      " 0.75551105 0.7595191  0.76352704 0.7675351  0.77154315 0.7755511\n",
      " 0.77955914 0.7835672  0.7875751  0.7915832  0.79559124 0.7995992\n",
      " 0.8036072  0.8076153  0.8116232  0.8156313  0.8196393  0.82364726\n",
      " 0.8276553  0.83166337 0.8356714  0.83967936 0.8436874  0.84769547\n",
      " 0.8517034  0.85571146 0.8597195  0.86372745 0.8677355  0.87174356\n",
      " 0.8757515  0.87975955 0.8837676  0.88777554 0.8917836  0.89579165\n",
      " 0.8997996  0.90380764 0.9078157  0.91182363 0.9158317  0.91983974\n",
      " 0.9238477  0.92785573 0.9318638  0.9358717  0.9398798  0.9438878\n",
      " 0.94789577 0.9519038  0.9559119  0.9599198  0.96392787 0.9679359\n",
      " 0.97194386 0.9759519  0.97995996 0.983968   0.98797596 0.991984\n",
      " 0.99599206 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(l1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Huber\n",
    "\n",
    "$$PH(y_r,y_p) = \\delta^2 \\cdot \\sqrt{1+\\left(\\frac{y_r-y_p}{\\delta}\\right)^2}-1, \\delta > 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1.+tf.square((target-x_vals)/delta1))-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2514441  0.25047213 0.2495004  0.24852893 0.24755764 0.24658659\n",
      " 0.24561578 0.24464527 0.24367496 0.2427049  0.24173515 0.24076563\n",
      " 0.23979636 0.23882735 0.23785861 0.23689017 0.23592193 0.23495403\n",
      " 0.23398636 0.23301901 0.23205197 0.23108518 0.23011866 0.22915247\n",
      " 0.2281866  0.227221   0.22625573 0.22529078 0.22432612 0.22336179\n",
      " 0.22239776 0.2214341  0.22047074 0.21950775 0.21854503 0.21758276\n",
      " 0.21662077 0.21565916 0.2146979  0.213737   0.21277645 0.21181628\n",
      " 0.21085653 0.20989713 0.20893814 0.20797952 0.2070213  0.20606348\n",
      " 0.20510611 0.20414913 0.20319253 0.20223643 0.20128073 0.20032547\n",
      " 0.19937061 0.19841626 0.19746235 0.19650891 0.19555594 0.19460341\n",
      " 0.19365141 0.1926999  0.19174886 0.19079834 0.18984833 0.18889885\n",
      " 0.18794988 0.18700147 0.18605357 0.18510623 0.1841595  0.18321328\n",
      " 0.18226765 0.1813226  0.18037817 0.17943433 0.17849112 0.17754848\n",
      " 0.17660652 0.17566518 0.1747245  0.17378448 0.17284511 0.17190646\n",
      " 0.17096847 0.17003122 0.16909468 0.16815884 0.16722377 0.16628942\n",
      " 0.16535585 0.16442305 0.16349106 0.16255985 0.16162945 0.16069992\n",
      " 0.15977119 0.15884332 0.15791634 0.15699024 0.15606503 0.15514076\n",
      " 0.1542174  0.15329501 0.15237357 0.15145311 0.15053366 0.14961524\n",
      " 0.14869784 0.14778148 0.14686622 0.14595205 0.14503895 0.14412704\n",
      " 0.14321625 0.14230664 0.14139825 0.14049107 0.1395851  0.13868041\n",
      " 0.13777703 0.13687494 0.13597418 0.13507481 0.1341768  0.13328023\n",
      " 0.1323851  0.13149144 0.13059929 0.12970866 0.12881958 0.12793212\n",
      " 0.12704626 0.12616205 0.12527955 0.12439876 0.12351973 0.12264249\n",
      " 0.12176708 0.12089356 0.12002195 0.11915227 0.11828458 0.11741894\n",
      " 0.11655535 0.11569387 0.11483459 0.11397748 0.11312266 0.11227013\n",
      " 0.11141995 0.1105722  0.10972689 0.1088841  0.10804389 0.10720628\n",
      " 0.10637137 0.10553921 0.10470985 0.10388337 0.10305983 0.10223926\n",
      " 0.1014218  0.10060748 0.09979634 0.09898852 0.09818406 0.09738303\n",
      " 0.09658554 0.09579165 0.09500144 0.09421503 0.09343249 0.09265389\n",
      " 0.09187935 0.09110896 0.09034281 0.08958104 0.08882371 0.08807094\n",
      " 0.08732286 0.08657955 0.08584115 0.08510776 0.08437952 0.08365657\n",
      " 0.08293901 0.08222695 0.08152058 0.08082001 0.08012536 0.07943682\n",
      " 0.07875449 0.07807856 0.07740918 0.07674648 0.07609066 0.07544185\n",
      " 0.07480022 0.07416598 0.07353928 0.0729203  0.07230922 0.07170624\n",
      " 0.07111152 0.07052529 0.06994771 0.06937901 0.06881936 0.068269\n",
      " 0.0677281  0.0671969  0.06667558 0.06616439 0.06566352 0.06517321\n",
      " 0.06469365 0.06422509 0.0637677  0.06332178 0.06288748 0.06246505\n",
      " 0.06205471 0.06165668 0.06127116 0.0608984  0.06053858 0.06019194\n",
      " 0.05985866 0.05953895 0.05923301 0.05894104 0.05866323 0.05839976\n",
      " 0.05815081 0.05791652 0.05769709 0.05749266 0.05730337 0.05712934\n",
      " 0.05697074 0.05682764 0.05670018 0.05658843 0.05649249 0.05641244\n",
      " 0.05634832 0.05630018 0.05626807 0.056252   0.056252   0.05626807\n",
      " 0.05630018 0.05634832 0.05641244 0.05649249 0.05658843 0.05670018\n",
      " 0.05682764 0.05697074 0.05712935 0.05730337 0.05749266 0.05769709\n",
      " 0.05791652 0.05815081 0.05839977 0.05866323 0.05894104 0.05923302\n",
      " 0.05953895 0.05985866 0.06019194 0.06053858 0.0608984  0.06127117\n",
      " 0.06165668 0.06205471 0.06246505 0.06288749 0.06332178 0.06376772\n",
      " 0.06422509 0.06469365 0.06517322 0.06566354 0.06616439 0.0666756\n",
      " 0.06719691 0.0677281  0.068269   0.06881937 0.06937901 0.06994771\n",
      " 0.07052529 0.07111152 0.07170624 0.07230923 0.0729203  0.07353928\n",
      " 0.074166   0.07480022 0.07544185 0.07609066 0.07674648 0.07740918\n",
      " 0.07807858 0.07875449 0.07943682 0.08012538 0.08081999 0.08152058\n",
      " 0.08222696 0.08293901 0.08365657 0.08437954 0.08510777 0.08584115\n",
      " 0.08657955 0.08732286 0.08807094 0.08882371 0.08958106 0.09034281\n",
      " 0.09110897 0.09187936 0.09265389 0.09343249 0.09421504 0.09500144\n",
      " 0.09579165 0.09658554 0.09738303 0.09818406 0.09898854 0.09979634\n",
      " 0.10060748 0.10142181 0.10223926 0.10305983 0.10388339 0.10470985\n",
      " 0.10553921 0.10637139 0.10720626 0.10804389 0.10888411 0.10972687\n",
      " 0.1105722  0.11141997 0.11227015 0.11312266 0.11397751 0.1148346\n",
      " 0.11569387 0.11655536 0.11741895 0.11828458 0.11915229 0.12002195\n",
      " 0.12089356 0.1217671  0.12264251 0.12351973 0.12439876 0.12527956\n",
      " 0.12616205 0.12704626 0.12793212 0.12881958 0.12970866 0.1305993\n",
      " 0.13149144 0.1323851  0.13328026 0.1341768  0.13507481 0.1359742\n",
      " 0.13687494 0.13777703 0.13868044 0.1395851  0.14049107 0.14139827\n",
      " 0.14230667 0.14321625 0.14412704 0.14503898 0.14595205 0.14686622\n",
      " 0.1477815  0.14869784 0.14961524 0.15053368 0.15145311 0.15237357\n",
      " 0.15329501 0.1542174  0.15514076 0.15606505 0.15699024 0.15791634\n",
      " 0.15884334 0.15977119 0.16069992 0.16162947 0.16255985 0.16349106\n",
      " 0.16442308 0.16535585 0.16628942 0.16722377 0.16815884 0.16909468\n",
      " 0.17003122 0.17096847 0.17190646 0.17284513 0.17378448 0.1747245\n",
      " 0.17566518 0.17660654 0.17754848 0.17849112 0.17943434 0.18037817\n",
      " 0.1813226  0.18226768 0.18321328 0.1841595  0.18510626 0.18605357\n",
      " 0.18700147 0.18794988 0.18889885 0.18984833 0.19079834 0.19174886\n",
      " 0.1926999  0.19365142 0.19460341 0.19555594 0.19650891 0.19746235\n",
      " 0.19841626 0.19937065 0.20032547 0.20128073 0.20223641 0.20319253\n",
      " 0.20414913 0.20510612 0.20606348 0.2070213  0.20797954 0.20893814\n",
      " 0.20989713 0.21085656 0.21181631 0.21277645 0.21373701 0.21469791\n",
      " 0.21565916 0.21662079 0.21758276 0.21854503 0.21950775 0.22047074\n",
      " 0.2214341  0.22239776 0.22336179 0.22432612 0.22529078 0.22625574\n",
      " 0.227221   0.2281866  0.22915252 0.23011866 0.23108518 0.23205197\n",
      " 0.23301901 0.23398636 0.23495401 0.23592193 0.23689017 0.23785861\n",
      " 0.23882735 0.23979636 0.24076563 0.24173515 0.2427049  0.24367496\n",
      " 0.24464524 0.24561578 0.24658659 0.24755764 0.2485289  0.2495004\n",
      " 0.25047216 0.2514441 ]\n"
     ]
    }
   ],
   "source": [
    "phuber1_y_out = session.run(phuber1_y_vals)\n",
    "print(phuber1_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida para problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-3.,5.,500)\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([500,],1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge (función bisagra)\n",
    "\n",
    "$$H(y_r,y_p)=max(0, 1-y_r\\cdot y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.         3.983968   3.9679358  3.9519038  3.9358718  3.9198396\n",
      " 3.9038076  3.8877757  3.8717434  3.8557115  3.8396792  3.8236473\n",
      " 3.8076153  3.791583   3.775551   3.759519   3.743487   3.727455\n",
      " 3.711423   3.6953907  3.6793587  3.6633267  3.6472945  3.6312625\n",
      " 3.6152306  3.5991983  3.5831664  3.5671344  3.5511022  3.5350702\n",
      " 3.5190382  3.503006   3.486974   3.470942   3.4549098  3.4388778\n",
      " 3.4228456  3.4068136  3.3907816  3.3747494  3.3587174  3.3426852\n",
      " 3.3266532  3.3106213  3.294589   3.278557   3.262525   3.2464929\n",
      " 3.230461   3.214429   3.1983967  3.1823647  3.1663327  3.1503005\n",
      " 3.1342685  3.1182365  3.1022043  3.0861723  3.0701404  3.0541081\n",
      " 3.0380762  3.0220442  3.006012   2.98998    2.973948   2.9579158\n",
      " 2.9418838  2.9258518  2.9098196  2.8937874  2.8777556  2.8617234\n",
      " 2.8456912  2.8296595  2.8136272  2.797595   2.7815633  2.765531\n",
      " 2.7494988  2.7334669  2.717435   2.7014027  2.6853707  2.6693387\n",
      " 2.6533065  2.6372745  2.6212425  2.6052103  2.5891783  2.5731463\n",
      " 2.5571141  2.5410821  2.5250502  2.509018   2.492986   2.476954\n",
      " 2.4609218  2.4448898  2.4288578  2.4128256  2.3967936  2.3807616\n",
      " 2.3647294  2.3486974  2.3326654  2.3166332  2.300601   2.2845693\n",
      " 2.268537   2.2525048  2.236473   2.2204409  2.2044086  2.188377\n",
      " 2.1723447  2.1563125  2.1402805  2.1242485  2.1082163  2.0921843\n",
      " 2.0761523  2.06012    2.0440881  2.0280561  2.012024   1.995992\n",
      " 1.97996    1.9639277  1.9478958  1.9318638  1.9158316  1.8997996\n",
      " 1.8837676  1.8677354  1.8517034  1.8356714  1.8196392  1.8036072\n",
      " 1.787575   1.771543   1.755511   1.7394788  1.7234468  1.7074149\n",
      " 1.6913826  1.6753507  1.6593187  1.6432865  1.6272545  1.6112225\n",
      " 1.5951903  1.5791583  1.5631263  1.5470941  1.5310621  1.5150301\n",
      " 1.4989979  1.482966   1.4669337  1.4509017  1.4348698  1.4188375\n",
      " 1.4028056  1.3867736  1.3707414  1.3547094  1.3386774  1.3226452\n",
      " 1.3066132  1.2905812  1.274549   1.258517   1.242485   1.2264528\n",
      " 1.2104208  1.1943886  1.1783566  1.1623247  1.1462924  1.1302605\n",
      " 1.1142285  1.0981963  1.0821643  1.0661323  1.0501001  1.0340681\n",
      " 1.0180361  1.0020039  0.9859719  0.96993995 0.9539077  0.93787575\n",
      " 0.9218435  0.90581155 0.88977957 0.87374735 0.85771537 0.8416834\n",
      " 0.82565117 0.8096192  0.7935872  0.777555   0.761523   0.745491\n",
      " 0.7294588  0.7134268  0.69739485 0.6813626  0.66533065 0.64929867\n",
      " 0.63326645 0.61723447 0.60120225 0.58517027 0.5691383  0.55310607\n",
      " 0.5370741  0.5210421  0.5050099  0.4889779  0.47294593 0.4569137\n",
      " 0.44088173 0.42484975 0.40881753 0.39278555 0.37675357 0.36072135\n",
      " 0.34468937 0.32865715 0.31262517 0.2965932  0.28056097 0.264529\n",
      " 0.24849701 0.23246479 0.21643281 0.20040083 0.18436861 0.16833663\n",
      " 0.15230465 0.13627243 0.12024045 0.10420847 0.08817625 0.07214427\n",
      " 0.05611229 0.04008007 0.02404809 0.00801587 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "hinge_y_vals = tf.maximum(0., 1.0 - tf.multiply(target, x_vals))\n",
    "hinge_y_out = session.run(hinge_y_vals)\n",
    "print(hinge_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada (función logística)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log(y_p) - (1-y_r)\\cdot log(1-y_p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 4.266695   3.504558   3.07711    2.7786188\n",
      " 2.5490425  2.3624578  2.205273   2.0694702  1.9499258  1.8431584\n",
      " 1.7466972  1.658729   1.5778773  1.5030754  1.4334824  1.3684192\n",
      " 1.307331   1.2497613  1.1953264  1.1437016  1.0946122  1.0478203\n",
      " 1.0031197  0.96033263 0.9193009  0.8798871  0.8419681  0.805434\n",
      " 0.7701883  0.7361426  0.7032175  0.67134243 0.64045215 0.61048704\n",
      " 0.58139426 0.55312395 0.5256306  0.49887323 0.4728133  0.44741485\n",
      " 0.4226459  0.39847532 0.37487555 0.35181987 0.3292835  0.30724418\n",
      " 0.2856801  0.26457092 0.24389847 0.2236447  0.20379275 0.18432751\n",
      " 0.16523395 0.14649788 0.12810664 0.11004756 0.09230857 0.07487902\n",
      " 0.05774807 0.0409054  0.02434197 0.00804817        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan]\n"
     ]
    }
   ],
   "source": [
    "xentr_y_vals = -tf.multiply(target, tf.log(x_vals)) - tf.multiply((1.-target), tf.log(1.-x_vals))\n",
    "xentr_y_out = session.run(xentr_y_vals)\n",
    "print(xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropía cruzada de sigmoide (evitar nans)\n",
    "\n",
    "$$H(y_r,y_p) = -y_r\\cdot log\\left(\\frac{1}{1+e^{-y_p}}\\right) - (1-y_r)\\cdot log\\left(1-\\frac{1}{1+e^{-y_p}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0485873  3.0333216  3.0180674  3.0028253  2.9875953  2.9723773\n",
      " 2.9571722  2.9419796  2.9267998  2.9116333  2.8964796  2.8813396\n",
      " 2.866213   2.8511002  2.8360016  2.8209174  2.805847   2.7907915\n",
      " 2.7757509  2.7607253  2.7457147  2.7307198  2.7157404  2.700777\n",
      " 2.6858296  2.6708984  2.6559842  2.6410863  2.6262057  2.6113422\n",
      " 2.5964963  2.581668   2.5668578  2.5520658  2.5372922  2.5225375\n",
      " 2.5078013  2.493085   2.4783878  2.4637103  2.4490528  2.4344156\n",
      " 2.419799   2.4052036  2.3906288  2.3760755  2.3615441  2.3470345\n",
      " 2.332547   2.3180823  2.3036401  2.2892213  2.2748258  2.2604537\n",
      " 2.246106   2.2317827  2.2174835  2.2032096  2.188961   2.174738\n",
      " 2.1605408  2.14637    2.1322253  2.1181078  2.1040173  2.0899544\n",
      " 2.0759194  2.0619125  2.0479343  2.0339847  2.0200646  2.006174\n",
      " 1.9923133  1.978483   1.964683   1.9509143  1.9371768  1.923471\n",
      " 1.9097973  1.8961561  1.8825476  1.8689723  1.8554305  1.8419226\n",
      " 1.828449   1.8150101  1.8016063  1.7882378  1.7749051  1.7616086\n",
      " 1.7483487  1.7351258  1.7219402  1.7087922  1.6956824  1.6826111\n",
      " 1.6695787  1.6565857  1.6436323  1.630719   1.6178461  1.6050141\n",
      " 1.5922233  1.5794743  1.5667672  1.5541027  1.5414809  1.5289024\n",
      " 1.5163676  1.5038767  1.4914304  1.4790288  1.4666724  1.4543618\n",
      " 1.4420971  1.4298787  1.4177072  1.4055829  1.393506   1.3814772\n",
      " 1.3694968  1.357565   1.3456825  1.3338494  1.3220662  1.3103331\n",
      " 1.2986509  1.2870194  1.2754395  1.2639112  1.252435   1.2410114\n",
      " 1.2296406  1.2183228  1.2070587  1.1958485  1.1846924  1.1735909\n",
      " 1.1625443  1.1515529  1.1406174  1.1297374  1.1189138  1.1081467\n",
      " 1.0974362  1.0867832  1.0761876  1.0656495  1.0551697  1.0447482\n",
      " 1.0343852  1.0240812  1.0138364  1.0036507  0.993525   0.9834591\n",
      " 0.97345334 0.9635081  0.9536234  0.94379973 0.9340371  0.92433566\n",
      " 0.9146959  0.9051178  0.8956015  0.8861475  0.87675565 0.8674262\n",
      " 0.8581595  0.8489556  0.83981436 0.83073646 0.8217216  0.81277007\n",
      " 0.803882   0.7950575  0.7862966  0.7775996  0.7689662  0.7603969\n",
      " 0.75189155 0.7434501  0.735073   0.7267599  0.7185109  0.7103263\n",
      " 0.7022059  0.6941497  0.6861577  0.67823017 0.6703666  0.66256744\n",
      " 0.6548323  0.64716154 0.63955474 0.632012   0.62453336 0.61711866\n",
      " 0.6097677  0.6024806  0.5952571  0.5880972  0.5810008  0.5739678\n",
      " 0.5669979  0.5600912  0.5532474  0.54646635 0.5397481  0.5330923\n",
      " 0.5264987  0.51996744 0.51349795 0.5070903  0.5007442  0.49445942\n",
      " 0.48823592 0.48207334 0.47597137 0.46992996 0.46394876 0.45802754\n",
      " 0.45216608 0.44636413 0.4406213  0.43493748 0.4293124  0.4237456\n",
      " 0.418237   0.4127862  0.40739292 0.4020569  0.39677775 0.39155528\n",
      " 0.38638905 0.38127875 0.3762242  0.37122494 0.36628062 0.361391\n",
      " 0.35655573 0.35177428 0.3470466  0.34237215 0.33775058 0.33318156\n",
      " 0.3286648  0.32419977 0.31978628 0.3154238  0.31111214 0.30685073\n",
      " 0.30263945 0.2984776  0.294365   0.2903013  0.28628597 0.28231865\n",
      " 0.27839914 0.27452683 0.27070138 0.26692253 0.2631897  0.25950256\n",
      " 0.25586087 0.252264   0.24871165 0.24520354 0.24173906 0.2383179\n",
      " 0.23493983 0.23160417 0.22831067 0.22505905 0.22184868 0.21867928\n",
      " 0.21555042 0.21246186 0.20941298 0.20640348 0.20343307 0.20050117\n",
      " 0.19760749 0.19475172 0.19193329 0.18915193 0.18640728 0.18369885\n",
      " 0.1810263  0.17838936 0.17578746 0.17322034 0.17068763 0.16818888\n",
      " 0.16572374 0.16329196 0.16089298 0.15852652 0.15619229 0.15388978\n",
      " 0.1516187  0.14937878 0.14716949 0.14499056 0.1428417  0.14072245\n",
      " 0.13863249 0.1365716  0.13453922 0.13253517 0.13055909 0.12861057\n",
      " 0.12668931 0.12479503 0.1229274  0.12108601 0.11927059 0.11748087\n",
      " 0.11571644 0.11397702 0.11226235 0.11057204 0.1089058  0.1072634\n",
      " 0.10564445 0.10404868 0.10247584 0.10092555 0.09939756 0.09789165\n",
      " 0.09640741 0.09494463 0.09350307 0.09208237 0.09068228 0.08930258\n",
      " 0.08794292 0.08660308 0.08528284 0.08398185 0.0826999  0.08143677\n",
      " 0.08019212 0.07896577 0.07775748 0.07656694 0.07539396 0.07423832\n",
      " 0.07309971 0.07197795 0.07087281 0.06978408 0.06871147 0.0676548\n",
      " 0.06661386 0.06558841 0.06457823 0.06358314 0.06260289 0.06163729\n",
      " 0.06068617 0.05974926 0.05882638 0.05791738 0.05702201 0.05614009\n",
      " 0.05527147 0.0544159  0.05357321 0.05274327 0.05192582 0.05112073\n",
      " 0.05032782 0.04954689 0.04877779 0.04802036 0.04727439 0.04653975\n",
      " 0.04581628 0.04510379 0.04440213 0.04371117 0.04303072 0.04236063\n",
      " 0.04170077 0.04105099 0.04041111 0.03978101 0.03916057 0.03854959\n",
      " 0.03794797 0.03735558 0.03677225 0.03619787 0.03563231 0.03507543\n",
      " 0.0345271  0.0339872  0.0334556  0.03293218 0.03241682 0.03190939\n",
      " 0.03140978 0.03091788 0.03043356 0.02995671 0.02948724 0.029025\n",
      " 0.02856991 0.02812186 0.02768073 0.02724643 0.02681887 0.02639791\n",
      " 0.02598347 0.02557547 0.02517379 0.02477833 0.02438902 0.02400575\n",
      " 0.02362843 0.02325697 0.0228913  0.0225313  0.02217689 0.02182801\n",
      " 0.02148456 0.02114644 0.02081361 0.02048595 0.02016339 0.01984588\n",
      " 0.0195333  0.0192256  0.01892272 0.01862455 0.01833104 0.01804211\n",
      " 0.0177577  0.01747772 0.01720214 0.01693085 0.01666381 0.01640095\n",
      " 0.0161422  0.0158875  0.01563678 0.01539    0.01514707 0.01490796\n",
      " 0.01467259 0.01444091 0.01421286 0.01398839 0.01376744 0.01354996\n",
      " 0.01333589 0.01312517 0.01291777 0.01271363 0.01251268 0.0123149\n",
      " 0.01212022 0.0119286  0.01174    0.01155436 0.01137163 0.01119178\n",
      " 0.01101477 0.01084053 0.01066904 0.01050024 0.0103341  0.01017058\n",
      " 0.01000963 0.00985122 0.0096953  0.00954184 0.00939079 0.00924212\n",
      " 0.0090958  0.00895179 0.00881004 0.00867053 0.00853322 0.00839807\n",
      " 0.00826506 0.00813414 0.00800529 0.00787847 0.00775366 0.00763081\n",
      " 0.0075099  0.0073909  0.00727378 0.00715851 0.00704506 0.0069334\n",
      " 0.00682351 0.00671535]\n"
     ]
    }
   ],
   "source": [
    "xentr_sig_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_vals, labels = targets)\n",
    "xentr_sig_y_out = session.run(xentr_sig_y_vals)\n",
    "print(xentr_sig_y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5242937  1.5166608  1.5090337  1.5014126  1.4937977  1.4861887\n",
      " 1.4785861  1.4709898  1.4633999  1.4558166  1.4482398  1.4406698\n",
      " 1.4331065  1.4255501  1.4180008  1.4104587  1.4029235  1.3953958\n",
      " 1.3878754  1.3803626  1.3728573  1.3653599  1.3578702  1.3503885\n",
      " 1.3429148  1.3354492  1.3279921  1.3205432  1.3131028  1.3056711\n",
      " 1.2982482  1.290834   1.2834289  1.2760329  1.2686461  1.2612687\n",
      " 1.2539006  1.2465425  1.2391939  1.2318552  1.2245264  1.2172078\n",
      " 1.2098995  1.2026018  1.1953144  1.1880378  1.1807721  1.1735172\n",
      " 1.1662735  1.1590412  1.1518201  1.1446106  1.1374129  1.1302269\n",
      " 1.123053   1.1158913  1.1087418  1.1016048  1.0944805  1.087369\n",
      " 1.0802704  1.073185   1.0661126  1.0590539  1.0520086  1.0449772\n",
      " 1.0379597  1.0309563  1.0239671  1.0169923  1.0100323  1.003087\n",
      " 0.99615663 0.9892415  0.9823415  0.97545713 0.9685884  0.9617355\n",
      " 0.95489866 0.94807804 0.9412738  0.93448615 0.92771524 0.9209613\n",
      " 0.9142245  0.90750504 0.90080315 0.8941189  0.88745254 0.8808043\n",
      " 0.87417436 0.8675629  0.8609701  0.8543961  0.8478412  0.84130555\n",
      " 0.83478934 0.82829285 0.82181615 0.8153595  0.80892307 0.80250704\n",
      " 0.79611164 0.78973716 0.7833836  0.7770513  0.77074045 0.7644512\n",
      " 0.7581838  0.75193834 0.7457152  0.7395144  0.7333362  0.7271809\n",
      " 0.72104853 0.71493936 0.7088536  0.70279145 0.696753   0.6907386\n",
      " 0.6847484  0.6787825  0.67284125 0.6669247  0.6610331  0.65516657\n",
      " 0.64932543 0.6435097  0.63771975 0.6319556  0.6262175  0.6205057\n",
      " 0.6148203  0.6091614  0.60352933 0.59792423 0.5923462  0.58679545\n",
      " 0.5812721  0.57577646 0.5703087  0.5648687  0.5594569  0.55407333\n",
      " 0.5487181  0.5433916  0.5380938  0.53282475 0.52758485 0.5223741\n",
      " 0.5171926  0.5120406  0.5069182  0.50182533 0.4967625  0.49172956\n",
      " 0.48672667 0.48175406 0.4768117  0.47189987 0.46701854 0.46216783\n",
      " 0.45734796 0.4525589  0.44780076 0.44307375 0.43837783 0.4337131\n",
      " 0.42907974 0.4244778  0.41990718 0.41536823 0.4108608  0.40638503\n",
      " 0.401941   0.39752874 0.3931483  0.3887998  0.3844831  0.38019845\n",
      " 0.37594578 0.37172505 0.3675365  0.36337996 0.35925546 0.35516316\n",
      " 0.35110295 0.34707484 0.34307885 0.33911508 0.3351833  0.33128372\n",
      " 0.32741615 0.32358077 0.31977737 0.316006   0.31226668 0.30855933\n",
      " 0.30488384 0.3012403  0.29762855 0.2940486  0.2905004  0.2869839\n",
      " 0.28349894 0.2800456  0.2766237  0.27323318 0.26987404 0.26654616\n",
      " 0.26324934 0.25998372 0.25674897 0.25354514 0.2503721  0.24722971\n",
      " 0.24411796 0.24103667 0.23798569 0.23496498 0.23197438 0.22901377\n",
      " 0.22608304 0.22318207 0.22031064 0.21746874 0.2146562  0.2118728\n",
      " 0.2091185  0.2063931  0.20369646 0.20102845 0.19838887 0.19577764\n",
      " 0.19319452 0.19063938 0.1881121  0.18561247 0.18314031 0.1806955\n",
      " 0.17827787 0.17588714 0.1735233  0.17118607 0.16887529 0.16659078\n",
      " 0.1643324  0.16209988 0.15989314 0.1577119  0.15555607 0.15342537\n",
      " 0.15131973 0.1492388  0.1471825  0.14515065 0.14314298 0.14115933\n",
      " 0.13919957 0.13726342 0.13535069 0.13346127 0.13159485 0.12975128\n",
      " 0.12793043 0.126132   0.12435582 0.12260177 0.12086953 0.11915895\n",
      " 0.11746991 0.11580209 0.11415534 0.11252952 0.11092434 0.10933964\n",
      " 0.10777521 0.10623093 0.10470649 0.10320174 0.10171653 0.10025059\n",
      " 0.09880374 0.09737586 0.09596664 0.09457596 0.09320364 0.09184942\n",
      " 0.09051315 0.08919468 0.08789373 0.08661017 0.08534382 0.08409444\n",
      " 0.08286187 0.08164598 0.08044649 0.07926326 0.07809614 0.07694489\n",
      " 0.07580935 0.07468939 0.07358474 0.07249528 0.07142085 0.07036123\n",
      " 0.06931625 0.0682858  0.06726961 0.06626759 0.06527954 0.06430528\n",
      " 0.06334466 0.06239751 0.0614637  0.060543   0.0596353  0.05874044\n",
      " 0.05785822 0.05698851 0.05613118 0.05528602 0.0544529  0.0536317\n",
      " 0.05282222 0.05202434 0.05123792 0.05046277 0.04969878 0.04894583\n",
      " 0.04820371 0.04747232 0.04675154 0.04604118 0.04534114 0.04465129\n",
      " 0.04397146 0.04330154 0.04264142 0.04199092 0.04134995 0.04071838\n",
      " 0.04009606 0.03948288 0.03887874 0.03828347 0.03769698 0.03711916\n",
      " 0.03654986 0.03598898 0.0354364  0.03489204 0.03435573 0.0338274\n",
      " 0.03330693 0.0327942  0.03228911 0.03179157 0.03130144 0.03081865\n",
      " 0.03034308 0.02987463 0.02941319 0.02895869 0.02851101 0.02807005\n",
      " 0.02763574 0.02720795 0.02678661 0.02637164 0.02596291 0.02556036\n",
      " 0.02516391 0.02477345 0.0243889  0.02401018 0.0236372  0.02326987\n",
      " 0.02290814 0.0225519  0.02220107 0.02185559 0.02151536 0.02118032\n",
      " 0.02085038 0.02052549 0.02020556 0.01989051 0.01958028 0.0192748\n",
      " 0.01897398 0.01867779 0.01838612 0.01809894 0.01781616 0.01753771\n",
      " 0.01726355 0.0169936  0.0167278  0.01646609 0.01620841 0.0159547\n",
      " 0.01570489 0.01545894 0.01521678 0.01497835 0.01474362 0.0145125\n",
      " 0.01428495 0.01406093 0.01384037 0.01362322 0.01340943 0.01319895\n",
      " 0.01299174 0.01278774 0.01258689 0.01238917 0.01219451 0.01200288\n",
      " 0.01181422 0.01162849 0.01144565 0.01126565 0.01108845 0.01091401\n",
      " 0.01074228 0.01057322 0.0104068  0.01024297 0.0100817  0.00992294\n",
      " 0.00976665 0.0096128  0.00946136 0.00931227 0.00916552 0.00902106\n",
      " 0.00887885 0.00873886 0.00860107 0.00846543 0.00833191 0.00820047\n",
      " 0.0080711  0.00794375 0.00781839 0.007695   0.00757354 0.00745398\n",
      " 0.00733629 0.00722045 0.00710643 0.0069942  0.00688372 0.00677498\n",
      " 0.00666794 0.00656259 0.00645888 0.00635681 0.00625634 0.00615745\n",
      " 0.00606011 0.0059643  0.00587    0.00577718 0.00568582 0.00559589\n",
      " 0.00550738 0.00542026 0.00533452 0.00525012 0.00516705 0.00508529\n",
      " 0.00500482 0.00492561 0.00484765 0.00477092 0.0046954  0.00462106\n",
      " 0.0045479  0.00447589 0.00440502 0.00433527 0.00426661 0.00419904\n",
      " 0.00413253 0.00406707 0.00400264 0.00393924 0.00387683 0.0038154\n",
      " 0.00375495 0.00369545 0.00363689 0.00357925 0.00352253 0.0034667\n",
      " 0.00341175 0.00335767]\n"
     ]
    }
   ],
   "source": [
    "pos_weight = tf.constant(0.5)\n",
    "xentr_sig_w_y_vals = tf.nn.weighted_cross_entropy_with_logits(logits=x_vals, targets = targets, pos_weight = pos_weight)\n",
    "xentr_sig_w_y_out = session.run(xentr_sig_w_y_vals)\n",
    "print(xentr_sig_w_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Cross Entropy (probabilidad)\n",
    "\n",
    "$$SM(z_k) = \\frac{e^{z_k}}{\\sum_{i=1}^n e^{z_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1601256]\n"
     ]
    }
   ],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[0.1,0.02,0.88]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse softmax cross entropy (vector 0s y un 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_logits = tf.constant([[1.,-3.,10.]])\n",
    "target_dist = tf.constant([[2]])\n",
    "softmax_xentr = tf.nn.softmax_cross_entropy_with_logits_v2(logits = unscaled_logits, labels = target_dist)\n",
    "softmax_xentr_y_out = session.run(softmax_xentr)\n",
    "print(softmax_xentr_y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar las funciones de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_array = session.run(x_vals)\n",
    "plt.plot(x_array, l2_y_out, 'r-', label='L2')\n",
    "plt.plot(x_array, l1_y_out, 'g--', label='L1')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
